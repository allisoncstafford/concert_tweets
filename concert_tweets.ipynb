{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concert Tweet Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necesary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import count, when, col\n",
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import (Tokenizer, Normalizer,\n",
    "                                LemmatizerModel, StopWordsCleaner, PerceptronApproach)\n",
    "from pyspark.ml import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "from sparknlp.pretrained import PretrainedPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the spark-NLP session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust show output format to pandas-like\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "# enable pyarrow for toPandas\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, I have saved the clean data to parquet and commented out the preprocessing/data cleaning steps to save time when re-running the notebook.\n",
    "\n",
    "In the first go, there were 25k rows of null - where the schema did not match the data. I decided to do some quick cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_seps(in_file, out_file, sep):\n",
    "    \"\"\"removes newline characters that come before the line reaches four segments(3 separators)\n",
    "    and combines \"middle sections\" with extra separators into a single segment by removing the separators.\n",
    "    \n",
    "    Args:\n",
    "        in_file: path to read file\n",
    "        out_file: path to write file\n",
    "        sep: separator/delimitor\n",
    "    \"\"\"\n",
    "    n_chunks = 4\n",
    "    \n",
    "    with open(in_file, 'r') as rf:\n",
    "        with open(out_file, 'w') as wf:\n",
    "            while True:\n",
    "                line = rf.readline()\n",
    "                \n",
    "                # if end of file\n",
    "                if line == '':\n",
    "                    break\n",
    "                    \n",
    "                # if line has less than n_sep, strip the newline and add the next line\n",
    "                if len(line.split(sep)) < n_chunks:\n",
    "                    line = line.strip('\\n')\n",
    "                    line += rf.readline()\n",
    "                \n",
    "                wf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_extra_seps('../../data/test_set_tweets.txt',\n",
    "#                       '../../data/test_set_tweets_clean.txt',\n",
    "#                      '\\t')\n",
    "# remove_extra_seps('../../data/training_set_tweets.txt',\n",
    "#                       '../../data/training_set_tweets_clean.txt',\n",
    "#                      '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the schema\n",
    "tweet_schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"t_id\", StringType(), True),\n",
    "    StructField(\"t_text\", StringType(), True),\n",
    "    StructField(\"t_dt\", TimestampType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_test = spark.read.csv('../../data/test_set_tweets_clean.txt', \n",
    "#                               sep='\\t',\n",
    "#                               schema=tweet_schema,\n",
    "#                               header=\"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_training = spark.read.csv('../../data/training_set_tweets_clean.txt', \n",
    "#                                  sep=\"\\t\", \n",
    "#                                  schema=tweet_schema,\n",
    "#                                  header='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data is unlabeled for our task, these test/train splits are not particularly useful, but a vestige of the original data set and purpose. We'll combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets = tweets_test.union(tweets_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future: Consider reading the data as a single column and then parsing. Compare outcome / number of tweets retrieved to that with the csv reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets.select('*').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----+\n",
      "|user_id| t_id|t_text| t_dt|\n",
      "+-------+-----+------+-----+\n",
      "|  33289|33179| 32631|53805|\n",
      "+-------+-----+------+-----+\n"
     ]
    }
   ],
   "source": [
    "# tweets.select([count(when(col(c).isNull(), c)).alias(c) for c in \n",
    "#         tweets.columns]).show()\n",
    "\n",
    "print(\"\"\"+-------+-----+------+-----+\n",
    "|user_id| t_id|t_text| t_dt|\n",
    "+-------+-----+------+-----+\n",
    "|  33289|33179| 32631|53805|\n",
    "+-------+-----+------+-----+\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8884863\n"
     ]
    }
   ],
   "source": [
    "# tweets.count()\n",
    "\n",
    "print(8884863)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8850656\n"
     ]
    }
   ],
   "source": [
    "# tweets.distinct().count()\n",
    "print(8850656)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the time stamp can be parsed from the end of the tweet text for many of these \"null\" datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tweets.filter(col('t_dt').isNull()).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when the datetime is null, take the last 19 characters of the tweet text as the datetime\n",
    "\n",
    "# tweets = tweets.withColumn('datetime', \n",
    "#                            F.when(F.col('t_dt').isNull(), \n",
    "#                                   F.to_date(F.substring('t_text', -19, 19)))\n",
    "#                            .otherwise(F.col('t_dt'))\n",
    "#                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when the datetime is null, remove the last characters (the tab and datetime) from the tweet text \n",
    "\n",
    "# tweets = tweets.withColumn('t_text', \n",
    "#                            F.when(F.col('t_dt').isNull(), \n",
    "#                                   F.expr('substring(t_text, 1, length(t_text)-20)'))\n",
    "#                            .otherwise(F.col('t_text'))\n",
    "#                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets = tweets.withColumn('t_dt', F.col('datetime')).drop('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as parquet and reload\n",
    "\n",
    "# tweets.write.parquet('../../data/tweets.parquet')\n",
    "tweets = spark.read.parquet('../../data/tweets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----+\n",
      "        |user_id| t_id|t_text| t_dt|\n",
      "        +-------+-----+------+-----+\n",
      "        |  34555|34490| 34232|54671|\n",
      "        +-------+-----+------+-----+\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# tweets.select([count(when(col(c).isNull(), c)).alias(c) for c in \n",
    "#         tweets.columns]).show()\n",
    "\n",
    "print(\"\"\"+-------+-----+------+-----+\n",
    "        |user_id| t_id|t_text| t_dt|\n",
    "        +-------+-----+------+-----+\n",
    "        |  34555|34490| 34232|54671|\n",
    "        +-------+-----+------+-----+\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8884863\n"
     ]
    }
   ],
   "source": [
    "# tweets.count()\n",
    "\n",
    "print(8884863)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop remaining rows with null values in the text column\n",
    "tweets = tweets.dropna(how='any', subset=['t_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=25513575, t_id='10334442280', t_text='', t_dt=None),\n",
       " Row(user_id=25513575, t_id='10333612651', t_text='', t_dt=None),\n",
       " Row(user_id=16198727, t_id='6899029209', t_text='This vid cracked me up! haha I w', t_dt=None),\n",
       " Row(user_id=20106865, t_id='10362030419', t_text=\"Ladies and gentlemen... come and join me.  It'\", t_dt=None),\n",
       " Row(user_id=20106865, t_id='10005503765', t_text='I am talking #Survivor RIGHT NOW in stickam', t_dt=None)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.filter(col('t_dt').isNull()).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly I could do some more/better data engineering here, but for this exercise, I'm going to move on, dropping any records with null values or t_text with empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty string tweets from the data set\n",
    "tweets = tweets.filter(~(tweets.t_text == \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829912\n"
     ]
    }
   ],
   "source": [
    "# tweets.count()\n",
    "\n",
    "print(8829912)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 8.83 million from the original 8.88 million. I'll take it for today's exercise. I'm pretty sure some more/better data engineering could extract more tweets from our text file, but that's a challenge for another day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concert tweets - Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am deciding to focus on english tweets for now. (may add spanish, others in the future based on presence in the data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting up the pieces of my pipeline to extract text info from the tweets (we'll use a pretrained pipeline later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "     .setInputCol('t_text') \\\n",
    "     .setOutputCol('document')\n",
    "tokenizer = Tokenizer() \\\n",
    "     .setInputCols(['document']) \\\n",
    "     .setOutputCol('token')\n",
    "normalizer = Normalizer() \\\n",
    "     .setInputCols(['token']) \\\n",
    "     .setOutputCol('normalized') \\\n",
    "     .setLowercase(True)\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "     .setInputCols(['normalized']) \\\n",
    "     .setOutputCol('lemma')\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "     .setInputCols(['lemma']) \\\n",
    "     .setOutputCol('clean_lemma') \\\n",
    "     .setCaseSensitive(False) \\\n",
    "     .setStopWords(eng_stopwords)\n",
    "finisher = Finisher() \\\n",
    "     .setInputCols(['clean_lemma']) \\\n",
    "     .setCleanAnnotations(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline() \\\n",
    "     .setStages([\n",
    "           documentAssembler,\n",
    "           tokenizer,\n",
    "           normalizer,\n",
    "           lemmatizer,\n",
    "           stopwords_cleaner,\n",
    "           finisher\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pipeline.fit(tweets).transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 't_id',\n",
       " 't_text',\n",
       " 't_dt',\n",
       " 'document',\n",
       " 'token',\n",
       " 'normalized',\n",
       " 'lemma',\n",
       " 'clean_lemma',\n",
       " 'finished_clean_lemma']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Classifier: contains the word concert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "concert_tweets = tweets.withColumn('concert', F.array_contains('finished_clean_lemma', 'concert'))\n",
    "concert_tweets = concert_tweets.filter(concert_tweets['concert'] == 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(t_text=\"@herRoyalStarnes I just thought of the history broke down bmw's on bdays free concert tickets in the nose bleeds p (cont) http://tl.gd/4pp7k\"),\n",
       " Row(t_text='Y is me @RandiICandy, @EpitomeOfADiva, and Leila Bunny n here singing Mary J like we Mary J. We in concert yall buy a ticket yall.'),\n",
       " Row(t_text=\"@beccalexis sup Bee? How'd the shoot go? Will you be at the concert tonight?\")]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concert_tweets.select('t_text').take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12477\n"
     ]
    }
   ],
   "source": [
    "# concert_tweets.count()\n",
    "\n",
    "print(12477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|t_text                                                                                                                                      |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|@herRoyalStarnes I just thought of the history broke down bmw's on bdays free concert tickets in the nose bleeds p (cont) http://tl.gd/4pp7k|\n",
      "|Y is me @RandiICandy, @EpitomeOfADiva, and Leila Bunny n here singing Mary J like we Mary J. We in concert yall buy a ticket yall.          |\n",
      "|@beccalexis sup Bee? How'd the shoot go? Will you be at the concert tonight?                                                                |\n",
      "|RT @BoomKack: Janet was at Lady Gaga concert tonight she is everything!!!!!! Can't touch her!                                               |\n",
      "|Concert tonight at the bellyup! The grouch& mr fab                                                                                          |\n",
      "|They Played #FLEX @ The Jigga Concert... And #MrHitDatHoe                                                                                   |\n",
      "|My First Concert... Then I'm seeing one of the best to ever do it                                                                           |\n",
      "|In The Library With @NickAustinG... He Tryin To Get On His Jigga Shit... Oh We Goin To The Concert Tonite                                   |\n",
      "|@RockStarRenRen lol is we going to this concert                                                                                             |\n",
      "|Sooo go b4 u wet ur self  @ANGELicNES: Hhuuuuhh I wanna go to this Jayz @SongzYuuup and Jeezy concert sooo bad                              |\n",
      "|@Magpiez uhm who in their right mind would pass up a John mayer concert?!?                                                                  |\n",
      "|awwww :) RT @_tierra: How cute! RT @Djrayyadig: I'm even more excited that I'm at the concert w/ @allantemitchell                           |\n",
      "|@arinicolelife are u going to the drizzy concert up there??? (State)                                                                        |\n",
      "|@Britt_Garrison jus sent me some audio from the concert lmao thats why i love my bf :)                                                      |\n",
      "|RT @CoutureiCON: I hope that everyone is at the Wharton for the FREE concert! BJ the Chicago Kid, Dom Kennedy and Keely!!                   |\n",
      "|i wish i was goin to the concert at state :( an having crack chicken later                                                                  |\n",
      "|Needs a concert asap....sept 9th come soon please.....                                                                                      |\n",
      "|I'm sittin here listenin 2 *secret lovers* n it made me lmao becuz I bet that was a long quiet ride hm frm d concert 4 d couples            |\n",
      "|Bree's heading to maryland tonight for another jonny lang concert. I've got the kids! #fb http://myloc.me/1nQui                             |\n",
      "|Jonny Lang concert, anyone else here? http://pic.gd/693682                                                                                  |\n",
      "|80s Babies Concert at Nokia Theater http://bit.ly/4wXmmO                                                                                    |\n",
      "|Bill Cosby - Cosby Joins Hancocks Birthday Concert Celebrations http://is.gd/9qlkh                                                          |\n",
      "|Whitney Houston - More Concert Woes For Houston http://is.gd/9a5zX                                                                          |\n",
      "|Whitney Houston - Houston Sparks New Health Concerns At Australia Concert http://is.gd/91Cs5                                                |\n",
      "|Jason Derulo- Helps @ BET's \"SOS: Help for Haiti\" Concert & Telethon http://is.gd/8GB7i                                                     |\n",
      "|Whitney Houston - Houston Scraps New Zealand Concert http://is.gd/8yxA3                                                                     |\n",
      "|@Ms_CPerry Concert tickets are like 150 but for the VIP is like 220-ish.. I fly southwest and plane ticket is like 250-ish...               |\n",
      "|those who had concerts... Yall know me better than that... #c'monson hahaha  http://myloc.me/1GDH7                                          |\n",
      "|RT @QueenzChicka88: Finally Off!!!Gotta get home so I can get ready to see my Boii\"HOVVVVVV\"2nite!!!:) -- U go to alllll his concerts! Lol  |\n",
      "|@juliembaby julz u going to the hov concert??                                                                                               |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "concert_tweets.select(\"t_text\").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are looking pretty concert-oriented! I want to see if we could catch some more tweets with a more inclusive filter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Classifier: contains the word concert or similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "concert_plus = tweets.withColumn('concert', F.array_contains('finished_clean_lemma', 'concert'))\\\n",
    "                     .withColumn('tour', F.array_contains('finished_clean_lemma', 'tour'))\\\n",
    "                     .withColumn('gig', F.array_contains('finished_clean_lemma', 'gig'))\\\n",
    "                     .withColumn('show', F.array_contains('finished_clean_lemma', 'show'))\n",
    "concert_plus = concert_plus.withColumn('concert_like', col('concert')|col('tour')|col('gig'))\n",
    "concert_plus = concert_plus.filter(concert_plus.concert_like == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|t_text                                                                                                                                      |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|@Lauralu2u yeps I had curve than the tour.   Love my Droid                                                                                  |\n",
      "|@herRoyalStarnes I just thought of the history broke down bmw's on bdays free concert tickets in the nose bleeds p (cont) http://tl.gd/4pp7k|\n",
      "|Y is me @RandiICandy, @EpitomeOfADiva, and Leila Bunny n here singing Mary J like we Mary J. We in concert yall buy a ticket yall.          |\n",
      "|@joeymcintyre You've got to be a LITTLE bit silly on tour or you wouldn't be YOU! ;)                                                        |\n",
      "|Wrapped Product Development on samples, now headed to FedEx to snd to my client! Have fun on tour babe! Hope u like em! Wish I could twitpic|\n",
      "|@beccalexis sup Bee? How'd the shoot go? Will you be at the concert tonight?                                                                |\n",
      "|RT @BoomKack: Janet was at Lady Gaga concert tonight she is everything!!!!!! Can't touch her!                                               |\n",
      "|Up and at em..got booked for anotha gig in 10 days.. 3-5 Models, 3 looks a piece..need a intern/assistant BAD                               |\n",
      "|RT @DerrickSwerve: I Cant Wait 4 @Hollywood2BK and @HoffaBillz To Have These Hip Hop Groupies So I Can Smash All The Leftover Scraps On Tour|\n",
      "|Watching \"Shades of Brooklyn\" waiting for this pizza... #shoutouts to @HeartbreakHolly for his HBO gig, big bizne$$!!! Salute!              |\n",
      "|Concert tonight at the bellyup! The grouch& mr fab                                                                                          |\n",
      "|' My girl love me but fuck it my heart beats slow & right now the tour bus is lookin like a freak show '                                    |\n",
      "|@JCanMakeuFamous I'm wit it.. Paying gig?                                                                                                   |\n",
      "|@JaeBarz aww dnt trip.. Hardwork pays off.. You'll get ur gig.. Be ez on urself                                                             |\n",
      "|They Played #FLEX @ The Jigga Concert... And #MrHitDatHoe                                                                                   |\n",
      "|My First Concert... Then I'm seeing one of the best to ever do it                                                                           |\n",
      "|In The Library With @NickAustinG... He Tryin To Get On His Jigga Shit... Oh We Goin To The Concert Tonite                                   |\n",
      "|@RockStarRenRen lol is we going to this concert                                                                                             |\n",
      "|Sooo go b4 u wet ur self  @ANGELicNES: Hhuuuuhh I wanna go to this Jayz @SongzYuuup and Jeezy concert sooo bad                              |\n",
      "|@Magpiez uhm who in their right mind would pass up a John mayer concert?!?                                                                  |\n",
      "|awwww :) RT @_tierra: How cute! RT @Djrayyadig: I'm even more excited that I'm at the concert w/ @allantemitchell                           |\n",
      "|@arinicolelife are u going to the drizzy concert up there??? (State)                                                                        |\n",
      "|@Britt_Garrison jus sent me some audio from the concert lmao thats why i love my bf :)                                                      |\n",
      "|RT @CoutureiCON: I hope that everyone is at the Wharton for the FREE concert! BJ the Chicago Kid, Dom Kennedy and Keely!!                   |\n",
      "|i wish i was goin to the concert at state :( an having crack chicken later                                                                  |\n",
      "|You know you have a lot of music when you fill a 80gig external....                                                                         |\n",
      "|Needs a concert asap....sept 9th come soon please.....                                                                                      |\n",
      "|Nerves starting to set in..... Auditions for turning stone gig tomorrow....                                                                 |\n",
      "|Goooooh-jus :D had a fantastic day... Tour continuous tomorrow :) http://tweetphoto.com/13837678                                            |\n",
      "|@melmah  Hey, give me a shout.  I got a potential gig for you.                                                                              |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "concert_plus.select(\"t_text\").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this super small sample, it doesn't seem like these alternate words are adding a lot to our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future: maybe combination of show/tour/gig and musician/group name in addition to the concert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have labeled data, and I'm not sure the best technique for clustering text data in this situation. Or how we would evaluate which techniqes are doing the best job identifying our concert tweets, and whether they are worth the extra complexity/computational requirements.\n",
    "\n",
    "For now, I'm going to move on using the \"concert\" lemma classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concert_tweets.select('user_id', 't_text', 't_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12444\n"
     ]
    }
   ],
   "source": [
    "# df.count()\n",
    "print(12444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-54-e29f211de91f>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-54-e29f211de91f>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    concert tickets in the nose bleeds p (cont) http://tl.gd/4pp7k\", t_dt=datetime.datetime(2010, 1, 22, 10, 17, 15))]\u001b[0m\n\u001b[0m                                                                                                                      \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "# df.take(1)\n",
    "\n",
    "print(\"\"\"[Row(user_id=85691996, t_text=\"@herRoyalStarnes I just thought of the history broke down bmw's on bdays free\n",
    "concert tickets in the nose bleeds p (cont) http://tl.gd/4pp7k\", t_dt=datetime.datetime(2010, 1, 22, 10, 17, 15))]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename t_text to text for use with pretrained Spark-NLP models\n",
    "df = df.withColumnRenamed('t_text', 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHEN: looking for date-related words\n",
    "\n",
    "#### Future: update \"when\" to have a non-hard-coded version of setting the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_datetime download started this may take some time.\n",
      "Approx size to download 12.8 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# date matcher pretrained pipeline\n",
    "\n",
    "date_pipe = PretrainedPipeline(\"match_datetime\", lang=\"en\")\n",
    "\n",
    "date_annotation = date_pipe.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+------------+\n",
      "|text                                                                                                                                        |t_dt               |result      |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+------------+\n",
      "|@herRoyalStarnes I just thought of the history broke down bmw's on bdays free concert tickets in the nose bleeds p (cont) http://tl.gd/4pp7k|2010-01-22 10:17:15|[]          |\n",
      "|Y is me @RandiICandy, @EpitomeOfADiva, and Leila Bunny n here singing Mary J like we Mary J. We in concert yall buy a ticket yall.          |2010-01-15 16:22:28|[]          |\n",
      "|@beccalexis sup Bee? How'd the shoot go? Will you be at the concert tonight?                                                                |2010-01-30 00:00:00|[]          |\n",
      "|RT @BoomKack: Janet was at Lady Gaga concert tonight she is everything!!!!!! Can't touch her!                                               |2010-01-24 00:00:00|[]          |\n",
      "|Concert tonight at the bellyup! The grouch& mr fab                                                                                          |2009-12-09 15:06:12|[]          |\n",
      "|They Played #FLEX @ The Jigga Concert... And #MrHitDatHoe                                                                                   |2010-02-22 19:59:44|[]          |\n",
      "|My First Concert... Then I'm seeing one of the best to ever do it                                                                           |2010-02-22 19:26:40|[]          |\n",
      "|In The Library With @NickAustinG... He Tryin To Get On His Jigga Shit... Oh We Goin To The Concert Tonite                                   |2010-02-22 11:32:56|[]          |\n",
      "|@RockStarRenRen lol is we going to this concert                                                                                             |2009-07-30 11:56:06|[]          |\n",
      "|Sooo go b4 u wet ur self  @ANGELicNES: Hhuuuuhh I wanna go to this Jayz @SongzYuuup and Jeezy concert sooo bad                              |2010-01-13 16:37:44|[]          |\n",
      "|@Magpiez uhm who in their right mind would pass up a John mayer concert?!?                                                                  |2010-03-02 01:47:55|[]          |\n",
      "|awwww :) RT @_tierra: How cute! RT @Djrayyadig: I'm even more excited that I'm at the concert w/ @allantemitchell                           |2010-03-14 18:24:28|[]          |\n",
      "|@arinicolelife are u going to the drizzy concert up there??? (State)                                                                        |2010-03-02 09:21:26|[]          |\n",
      "|@Britt_Garrison jus sent me some audio from the concert lmao thats why i love my bf :)                                                      |2010-02-11 19:58:51|[]          |\n",
      "|RT @CoutureiCON: I hope that everyone is at the Wharton for the FREE concert! BJ the Chicago Kid, Dom Kennedy and Keely!!                   |2010-02-11 17:45:41|[]          |\n",
      "|i wish i was goin to the concert at state :( an having crack chicken later                                                                  |2010-02-11 16:21:15|[]          |\n",
      "|Needs a concert asap....sept 9th come soon please.....                                                                                      |2009-08-18 00:00:00|[2020/09/09]|\n",
      "|I'm sittin here listenin 2 *secret lovers* n it made me lmao becuz I bet that was a long quiet ride hm frm d concert 4 d couples            |2010-03-02 10:55:52|[]          |\n",
      "|Bree's heading to maryland tonight for another jonny lang concert. I've got the kids! #fb http://myloc.me/1nQui                             |2009-11-07 10:49:57|[]          |\n",
      "|Jonny Lang concert, anyone else here? http://pic.gd/693682                                                                                  |2009-11-05 18:48:41|[]          |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the result\n",
    "date_annotation.select('text', 't_dt', 'date.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is cool! It is using day-oriented words, like yesterday! I wonder if there is a way to set a reference date (as opposed to today). At least for the \"Radio One concert\" tweet... Doesn't look like there is, but I can use the date it outputs, get their relation with today, and apply to the date.\n",
    "\n",
    "I'm not sure how it got 12/06 from the \"Decemberists concert tonight\" tweet. - maybe december + the 6 hours later?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename date.result to date_result\n",
    "date_annotation = date_annotation.select('text', F.col('date.result').alias('date_result'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfortunately, I'm getting this error that I didn't get when coding on a smaller sample :(\n",
    "# Py4JJavaError: An error occurred while calling o6798.collectToPython.\n",
    "# : org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 126.0 failed 1 times, \n",
    "# most recent failure: Lost task 1.0 in stage 126.0 (TID 1298, localhost, executor driver): \n",
    "# org.apache.spark.SparkException: Failed to execute user defined function($anonfun$dfAnnotate$1: \n",
    "# (array<array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:\n",
    "#  array<float>>>>) => array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,\n",
    "# embeddings:array<float>>>)\n",
    "\n",
    "# I'm going to move on for today\n",
    "\n",
    "# date_annotation.select('date_result').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the exercise's sake, I will continue with the date transformation from this 1% sample.\n",
    "\n",
    "**Future: Investigate this error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with a sample of the dataframe\n",
    "date_annotation = date_pipe.transform(df.sample(fraction=.01, seed=5))\n",
    "\n",
    "# rename date.result to date_result\n",
    "date_annotation = date_annotation.select('text', F.col('date.result').alias('date_result'))\n",
    "\n",
    "# test for error\n",
    "# date_annotation.select('date_result').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max no of dates: 1\n"
     ]
    }
   ],
   "source": [
    "# date_annotation.select(F.size(\"date_result\").alias(\"no_of_dates\")).agg({\"no_of_dates\": \"max\"}).show()\n",
    "\n",
    "print(\"\"\"max no of dates: 1\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm deciding to take the first date, since in my small sample, no tweet had more than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first date from list of dates\n",
    "date_annotation = date_annotation.withColumn('date_result', F.col('date_result')[0])\n",
    "\n",
    "# join the extracted date df with the original data frame\n",
    "df = df.join(date_annotation, on='text', how='left')\n",
    "\n",
    "# convert to dateType\n",
    "df = df.withColumn('date_result', F.to_date(df['date_result'],'yyyy/MM/dd'))\n",
    "\n",
    "# add a column with the difference in date between the date produced by the date extractor and today\n",
    "df = df.withColumn('date_diff', F.datediff(F.current_timestamp(), df['date_result']))\n",
    "\n",
    "# if date_result is within two weeks of today, get difference, and apply it to timestamp\n",
    "# elif date_result has this year's date. reset the year to match the year of the tweet \n",
    "# (hardcoeded as 10 years)\n",
    "df = df.withColumn('when', F.when((col('date_diff') > -14),\n",
    "                                      F.expr(\"date_add(t_dt, date_diff)\"))\\\n",
    "                          .when((F.col('date_diff') < -14) \n",
    "                                & (F.year('date_result') == F.year(F.current_timestamp())), \n",
    "                                F.date_sub('date_result', 3652))\n",
    "            )\n",
    "\n",
    "# drop the extra columns\n",
    "df = df.drop('date_result', 'date_diff', 't_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string for compatibility with pyarrow\n",
    "df = df.withColumn('when', F.col('when').cast('string'))\n",
    "\n",
    "# I'm having some errors with toPandas() so I'm going to convert to pandas in stages\n",
    "date_df = df.toPandas()\n",
    "\n",
    "\n",
    "# df.write.json('../../data/date_text.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have 12k records and pyspark doesn't support typedLit (passing arrays to udfs) yet, I'm going to collect the text information we need for the rest of the data extraction, and move to pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onto_recognize_entities_lg download started this may take some time.\n",
      "Approx size to download 2.3 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# use pretrained pipeline for NER, Tokens\n",
    "pipeline_entities = PretrainedPipeline(\"onto_recognize_entities_lg\", lang=\"en\")\n",
    "annotation_entities = pipeline_entities.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the needed columns to pandas\n",
    "entities_df = annotation_entities.select(F.col('entities.result').alias('entities'),\n",
    "                                            F.col('ner.result').alias('ners'),\n",
    "                                            F.col('token.result').alias('tokens'),\n",
    "                                           'text')\\\n",
    "                                .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze_sentiment download started this may take some time.\n",
      "Approx size to download 4.9 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# use pretrained pipeline for sentiment extraction\n",
    "pipe_sentiment = PretrainedPipeline(\"analyze_sentiment\", lang=\"en\")\n",
    "annotation_sentiment = pipe_sentiment.transform(df)\n",
    "\n",
    "# future note: \"analyze_sentimentdl_use_twitter\" --> Can not find the model to download please check the name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_sentiment.select('text', 'sentiment.result').show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sentiment analysis seems like it is not doing a great job with these tweets (a lot of negative). I wish the twitter-trained one was working! But I'll continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sentiments to df\n",
    "# df = df.join(annotation_sentiment.select('text',\n",
    "#                                         F.col('sentiment.result').alias('sentiments')),\n",
    "#              on='text',\n",
    "#              how='inner')\n",
    "\n",
    "# convert sentiments to pandas\n",
    "sentiments_df = annotation_sentiment.select('text',\n",
    "                                            F.col('sentiment.result').alias('sentiments'))\\\n",
    "                                    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine dataframes in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12444, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>when</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@herRoyalStarnes I just thought of the history...</td>\n",
       "      <td>85691996</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Y is me @RandiICandy, @EpitomeOfADiva, and Lei...</td>\n",
       "      <td>85691996</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@beccalexis sup Bee? How'd the shoot go? Will ...</td>\n",
       "      <td>25611870</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @BoomKack: Janet was at Lady Gaga concert t...</td>\n",
       "      <td>25611870</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Concert tonight at the bellyup! The grouch&amp; mr...</td>\n",
       "      <td>30387809</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   user_id  when\n",
       "0  @herRoyalStarnes I just thought of the history...  85691996  None\n",
       "1  Y is me @RandiICandy, @EpitomeOfADiva, and Lei...  85691996  None\n",
       "2  @beccalexis sup Bee? How'd the shoot go? Will ...  25611870  None\n",
       "3  RT @BoomKack: Janet was at Lady Gaga concert t...  25611870  None\n",
       "4  Concert tonight at the bellyup! The grouch& mr...  30387809  None"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm head and shape\n",
    "print(date_df.shape)\n",
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12444, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@herRoyalStarnes I just thought of the history...</td>\n",
       "      <td>[positive, positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Y is me @RandiICandy, @EpitomeOfADiva, and Lei...</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@beccalexis sup Bee? How'd the shoot go? Will ...</td>\n",
       "      <td>[negative, negative, negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @BoomKack: Janet was at Lady Gaga concert t...</td>\n",
       "      <td>[negative, positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Concert tonight at the bellyup! The grouch&amp; mr...</td>\n",
       "      <td>[negative, positive]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @herRoyalStarnes I just thought of the history...   \n",
       "1  Y is me @RandiICandy, @EpitomeOfADiva, and Lei...   \n",
       "2  @beccalexis sup Bee? How'd the shoot go? Will ...   \n",
       "3  RT @BoomKack: Janet was at Lady Gaga concert t...   \n",
       "4  Concert tonight at the bellyup! The grouch& mr...   \n",
       "\n",
       "                       sentiments  \n",
       "0            [positive, positive]  \n",
       "1                      [positive]  \n",
       "2  [negative, negative, negative]  \n",
       "3            [negative, positive]  \n",
       "4            [negative, positive]  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentiments_df.shape)\n",
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12444, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>ners</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[bmw]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...</td>\n",
       "      <td>[@, herRoyalStarnes, I, just, thought, of, the...</td>\n",
       "      <td>@herRoyalStarnes I just thought of the history...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[RandiICandy, EpitomeOfADiva, Leila Bunny, Mar...</td>\n",
       "      <td>[O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...</td>\n",
       "      <td>[Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...</td>\n",
       "      <td>Y is me @RandiICandy, @EpitomeOfADiva, and Lei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[tonight]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[@, beccalexis, sup, Bee, ?, How, 'd, the, sho...</td>\n",
       "      <td>@beccalexis sup Bee? How'd the shoot go? Will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[BoomKack, Janet, Gaga, tonight]</td>\n",
       "      <td>[O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...</td>\n",
       "      <td>[RT, @, BoomKack, :, Janet, was, at, Lady, Gag...</td>\n",
       "      <td>RT @BoomKack: Janet was at Lady Gaga concert t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[tonight]</td>\n",
       "      <td>[O, B-TIME, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[Concert, tonight, at, the, bellyup, !, The, g...</td>\n",
       "      <td>Concert tonight at the bellyup! The grouch&amp; mr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            entities  \\\n",
       "0                                              [bmw]   \n",
       "1  [RandiICandy, EpitomeOfADiva, Leila Bunny, Mar...   \n",
       "2                                          [tonight]   \n",
       "3                   [BoomKack, Janet, Gaga, tonight]   \n",
       "4                                          [tonight]   \n",
       "\n",
       "                                                ners  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...   \n",
       "1  [O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...   \n",
       "4             [O, B-TIME, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [@, herRoyalStarnes, I, just, thought, of, the...   \n",
       "1  [Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...   \n",
       "2  [@, beccalexis, sup, Bee, ?, How, 'd, the, sho...   \n",
       "3  [RT, @, BoomKack, :, Janet, was, at, Lady, Gag...   \n",
       "4  [Concert, tonight, at, the, bellyup, !, The, g...   \n",
       "\n",
       "                                                text  \n",
       "0  @herRoyalStarnes I just thought of the history...  \n",
       "1  Y is me @RandiICandy, @EpitomeOfADiva, and Lei...  \n",
       "2  @beccalexis sup Bee? How'd the shoot go? Will ...  \n",
       "3  RT @BoomKack: Janet was at Lady Gaga concert t...  \n",
       "4  Concert tonight at the bellyup! The grouch& mr...  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(entities_df.shape)\n",
    "entities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = date_df.join(sentiments_df.drop(columns='text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = df_pd.join(entities_df.drop(columns='text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>when</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>entities</th>\n",
       "      <th>ners</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@herRoyalStarnes I just thought of the history...</td>\n",
       "      <td>85691996</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive, positive]</td>\n",
       "      <td>[bmw]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...</td>\n",
       "      <td>[@, herRoyalStarnes, I, just, thought, of, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Y is me @RandiICandy, @EpitomeOfADiva, and Lei...</td>\n",
       "      <td>85691996</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[RandiICandy, EpitomeOfADiva, Leila Bunny, Mar...</td>\n",
       "      <td>[O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...</td>\n",
       "      <td>[Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@beccalexis sup Bee? How'd the shoot go? Will ...</td>\n",
       "      <td>25611870</td>\n",
       "      <td>None</td>\n",
       "      <td>[negative, negative, negative]</td>\n",
       "      <td>[tonight]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[@, beccalexis, sup, Bee, ?, How, 'd, the, sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @BoomKack: Janet was at Lady Gaga concert t...</td>\n",
       "      <td>25611870</td>\n",
       "      <td>None</td>\n",
       "      <td>[negative, positive]</td>\n",
       "      <td>[BoomKack, Janet, Gaga, tonight]</td>\n",
       "      <td>[O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...</td>\n",
       "      <td>[RT, @, BoomKack, :, Janet, was, at, Lady, Gag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Concert tonight at the bellyup! The grouch&amp; mr...</td>\n",
       "      <td>30387809</td>\n",
       "      <td>None</td>\n",
       "      <td>[negative, positive]</td>\n",
       "      <td>[tonight]</td>\n",
       "      <td>[O, B-TIME, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[Concert, tonight, at, the, bellyup, !, The, g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   user_id  when  \\\n",
       "0  @herRoyalStarnes I just thought of the history...  85691996  None   \n",
       "1  Y is me @RandiICandy, @EpitomeOfADiva, and Lei...  85691996  None   \n",
       "2  @beccalexis sup Bee? How'd the shoot go? Will ...  25611870  None   \n",
       "3  RT @BoomKack: Janet was at Lady Gaga concert t...  25611870  None   \n",
       "4  Concert tonight at the bellyup! The grouch& mr...  30387809  None   \n",
       "\n",
       "                       sentiments  \\\n",
       "0            [positive, positive]   \n",
       "1                      [positive]   \n",
       "2  [negative, negative, negative]   \n",
       "3            [negative, positive]   \n",
       "4            [negative, positive]   \n",
       "\n",
       "                                            entities  \\\n",
       "0                                              [bmw]   \n",
       "1  [RandiICandy, EpitomeOfADiva, Leila Bunny, Mar...   \n",
       "2                                          [tonight]   \n",
       "3                   [BoomKack, Janet, Gaga, tonight]   \n",
       "4                                          [tonight]   \n",
       "\n",
       "                                                ners  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...   \n",
       "1  [O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...   \n",
       "4             [O, B-TIME, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                              tokens  \n",
       "0  [@, herRoyalStarnes, I, just, thought, of, the...  \n",
       "1  [Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...  \n",
       "2  [@, beccalexis, sup, Bee, ?, How, 'd, the, sho...  \n",
       "3  [RT, @, BoomKack, :, Janet, was, at, Lady, Gag...  \n",
       "4  [Concert, tonight, at, the, bellyup, !, The, g...  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who\n",
    "\n",
    "For the sake of time, I focused on pop and hip hop artists from 2009/2010 (data from wikipedia). This is extra tricky when tweeters use the artist handles (eg @JonasBrothers), again this is an area for future iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import artist list\n",
    "with open('../../data/musicians.txt', 'r') as f:\n",
    "     artists = f.read().splitlines()\n",
    "        \n",
    "artists = list(set(artists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lloyd', 'Michael Bubl', 'Beyonc', 'Fat Joe', 'Travie McCoy']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 'who' with the intersection of the extracted entities from the tweets and my artist list\n",
    "df_pd['who'] = [[entity for entity in e_list if entity in artists] for e_list in df_pd['entities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>when</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>entities</th>\n",
       "      <th>ners</th>\n",
       "      <th>tokens</th>\n",
       "      <th>who</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Jason Derulo- Helps @ BET's \"SOS: Help for Hai...</td>\n",
       "      <td>71429761</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[Jason Derulo]</td>\n",
       "      <td>[B-PERSON, I-PERSON, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[Jason, Derulo, -, Helps, @, BET, 's, \", SOS, ...</td>\n",
       "      <td>[Jason Derulo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>PAUSE! Now Drake is in concert? How? He doesn'...</td>\n",
       "      <td>46329494</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive, negative, negative, negative]</td>\n",
       "      <td>[Drake]</td>\n",
       "      <td>[O, O, O, B-PERSON, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[PAUSE, !, Now, Drake, is, in, concert, ?, How...</td>\n",
       "      <td>[Drake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>Boooom ! RT @AllThingsFresh: Drake just perfor...</td>\n",
       "      <td>62205707</td>\n",
       "      <td>None</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>[AllThingsFresh, Drake, \"Forever, Toronto]</td>\n",
       "      <td>[O, O, O, O, B-FAC, O, B-PERSON, O, O, B-WORK_...</td>\n",
       "      <td>[Boooom, !, RT, @, AllThingsFresh, :, Drake, j...</td>\n",
       "      <td>[Drake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>Sooo i'm in love with Jay-Z new cd i really wa...</td>\n",
       "      <td>53309244</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[Jay-Z]</td>\n",
       "      <td>[O, O, O, O, O, O, B-PERSON, O, O, O, O, O, O,...</td>\n",
       "      <td>[Sooo, i, 'm, in, love, with, Jay-Z, new, cd, ...</td>\n",
       "      <td>[Jay-Z]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>RT @dlloydthemlmpro: World AIDS Day: Alicia Ke...</td>\n",
       "      <td>65392460</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive, na]</td>\n",
       "      <td>[World AIDS Day, Alicia Keys]</td>\n",
       "      <td>[O, O, O, O, B-WORK_OF_ART, I-WORK_OF_ART, I-W...</td>\n",
       "      <td>[RT, @, dlloydthemlmpro, :, World, AIDS, Day, ...</td>\n",
       "      <td>[Alicia Keys]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12307</td>\n",
       "      <td>Watching NKOTB on youtube. In need of a concert</td>\n",
       "      <td>26341336</td>\n",
       "      <td>None</td>\n",
       "      <td>[negative, negative]</td>\n",
       "      <td>[NKOTB]</td>\n",
       "      <td>[O, B-ORG, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[Watching, NKOTB, on, youtube, ., In, need, of...</td>\n",
       "      <td>[NKOTB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12360</td>\n",
       "      <td>Check out Alicia Keys streaming live concert o...</td>\n",
       "      <td>24575856</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[Alicia Keys]</td>\n",
       "      <td>[O, O, B-PERSON, I-PERSON, O, O, O, O, O, O, O...</td>\n",
       "      <td>[Check, out, Alicia, Keys, streaming, live, co...</td>\n",
       "      <td>[Alicia Keys]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12390</td>\n",
       "      <td>I was just thinkin.... what if at this Jay-Z c...</td>\n",
       "      <td>18546575</td>\n",
       "      <td>None</td>\n",
       "      <td>[negative, negative, negative, negative, negat...</td>\n",
       "      <td>[Jay-Z, a few weeks, #FTW]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-PERSON,...</td>\n",
       "      <td>[I, was, just, thinkin, ., ., ., ., what, if, ...</td>\n",
       "      <td>[Jay-Z]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12417</td>\n",
       "      <td>people getting real live pissed about the Drak...</td>\n",
       "      <td>69156796</td>\n",
       "      <td>None</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>[Drake, Drake]</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-PERSON, O, O, O, B-PER...</td>\n",
       "      <td>[people, getting, real, live, pissed, about, t...</td>\n",
       "      <td>[Drake, Drake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12418</td>\n",
       "      <td>#oneofmyfollowers said the Drake concert in Ha...</td>\n",
       "      <td>69156796</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive, positive]</td>\n",
       "      <td>[#oneofmyfollowers, Drake, Hattiesburg, Memories]</td>\n",
       "      <td>[B-PERSON, O, O, B-PERSON, O, O, B-GPE, O, O, ...</td>\n",
       "      <td>[#oneofmyfollowers, said, the, Drake, concert,...</td>\n",
       "      <td>[Drake]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text   user_id  when  \\\n",
       "24     Jason Derulo- Helps @ BET's \"SOS: Help for Hai...  71429761  None   \n",
       "35     PAUSE! Now Drake is in concert? How? He doesn'...  46329494  None   \n",
       "114    Boooom ! RT @AllThingsFresh: Drake just perfor...  62205707  None   \n",
       "157    Sooo i'm in love with Jay-Z new cd i really wa...  53309244  None   \n",
       "168    RT @dlloydthemlmpro: World AIDS Day: Alicia Ke...  65392460  None   \n",
       "...                                                  ...       ...   ...   \n",
       "12307    Watching NKOTB on youtube. In need of a concert  26341336  None   \n",
       "12360  Check out Alicia Keys streaming live concert o...  24575856  None   \n",
       "12390  I was just thinkin.... what if at this Jay-Z c...  18546575  None   \n",
       "12417  people getting real live pissed about the Drak...  69156796  None   \n",
       "12418  #oneofmyfollowers said the Drake concert in Ha...  69156796  None   \n",
       "\n",
       "                                              sentiments  \\\n",
       "24                                            [positive]   \n",
       "35              [positive, negative, negative, negative]   \n",
       "114                                           [negative]   \n",
       "157                                           [positive]   \n",
       "168                                       [positive, na]   \n",
       "...                                                  ...   \n",
       "12307                               [negative, negative]   \n",
       "12360                                         [positive]   \n",
       "12390  [negative, negative, negative, negative, negat...   \n",
       "12417                                         [negative]   \n",
       "12418                               [positive, positive]   \n",
       "\n",
       "                                                entities  \\\n",
       "24                                        [Jason Derulo]   \n",
       "35                                               [Drake]   \n",
       "114           [AllThingsFresh, Drake, \"Forever, Toronto]   \n",
       "157                                              [Jay-Z]   \n",
       "168                        [World AIDS Day, Alicia Keys]   \n",
       "...                                                  ...   \n",
       "12307                                            [NKOTB]   \n",
       "12360                                      [Alicia Keys]   \n",
       "12390                         [Jay-Z, a few weeks, #FTW]   \n",
       "12417                                     [Drake, Drake]   \n",
       "12418  [#oneofmyfollowers, Drake, Hattiesburg, Memories]   \n",
       "\n",
       "                                                    ners  \\\n",
       "24     [B-PERSON, I-PERSON, O, O, O, O, O, O, O, O, O...   \n",
       "35     [O, O, O, B-PERSON, O, O, O, O, O, O, O, O, O,...   \n",
       "114    [O, O, O, O, B-FAC, O, B-PERSON, O, O, B-WORK_...   \n",
       "157    [O, O, O, O, O, O, B-PERSON, O, O, O, O, O, O,...   \n",
       "168    [O, O, O, O, B-WORK_OF_ART, I-WORK_OF_ART, I-W...   \n",
       "...                                                  ...   \n",
       "12307                 [O, B-ORG, O, O, O, O, O, O, O, O]   \n",
       "12360  [O, O, B-PERSON, I-PERSON, O, O, O, O, O, O, O...   \n",
       "12390  [O, O, O, O, O, O, O, O, O, O, O, O, B-PERSON,...   \n",
       "12417  [O, O, O, O, O, O, O, B-PERSON, O, O, O, B-PER...   \n",
       "12418  [B-PERSON, O, O, B-PERSON, O, O, B-GPE, O, O, ...   \n",
       "\n",
       "                                                  tokens             who  \n",
       "24     [Jason, Derulo, -, Helps, @, BET, 's, \", SOS, ...  [Jason Derulo]  \n",
       "35     [PAUSE, !, Now, Drake, is, in, concert, ?, How...         [Drake]  \n",
       "114    [Boooom, !, RT, @, AllThingsFresh, :, Drake, j...         [Drake]  \n",
       "157    [Sooo, i, 'm, in, love, with, Jay-Z, new, cd, ...         [Jay-Z]  \n",
       "168    [RT, @, dlloydthemlmpro, :, World, AIDS, Day, ...   [Alicia Keys]  \n",
       "...                                                  ...             ...  \n",
       "12307  [Watching, NKOTB, on, youtube, ., In, need, of...         [NKOTB]  \n",
       "12360  [Check, out, Alicia, Keys, streaming, live, co...   [Alicia Keys]  \n",
       "12390  [I, was, just, thinkin, ., ., ., ., what, if, ...         [Jay-Z]  \n",
       "12417  [people, getting, real, live, pissed, about, t...  [Drake, Drake]  \n",
       "12418  [#oneofmyfollowers, said, the, Drake, concert,...         [Drake]  \n",
       "\n",
       "[459 rows x 8 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.loc[df_pd['who'].str.len() >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty strings with null/None\n",
    "df_pd['who'] = df_pd['who'].apply(lambda x: None if len(x)==0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ners</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...</td>\n",
       "      <td>[@, herRoyalStarnes, I, just, thought, of, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...</td>\n",
       "      <td>[Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[@, beccalexis, sup, Bee, ?, How, 'd, the, sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...</td>\n",
       "      <td>[RT, @, BoomKack, :, Janet, was, at, Lady, Gag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[O, B-TIME, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[Concert, tonight, at, the, bellyup, !, The, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[O, O, O, O, B-WORK_OF_ART, I-WORK_OF_ART, I-W...</td>\n",
       "      <td>[They, Played, #FLEX, @, The, Jigga, Concert, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[O, B-ORDINAL, O, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[My, First, Concert, ., .., Then, I, 'm, seein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>[O, B-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_AR...</td>\n",
       "      <td>[In, The, Library, With, @, NickAustinG, ., .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>[O, B-PERSON, O, O, O, O, O, O, O]</td>\n",
       "      <td>[@, RockStarRenRen, lol, is, we, going, to, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PERSON, O, O,...</td>\n",
       "      <td>[Sooo, go, b4, u, wet, ur, self, @, ANGELicNES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>[O, B-PERSON, O, O, O, O, O, O, O, O, O, O, B-...</td>\n",
       "      <td>[@, Magpiez, uhm, who, in, their, right, mind,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-PERSON, O,...</td>\n",
       "      <td>[awwww, :), RT, @_, tierra, :, How, cute, !, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[@, arinicolelife, are, u, going, to, the, dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[@, Britt_Garrison, jus, sent, me, some, audio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>[O, O, B-PERSON, O, O, O, O, O, O, O, O, B-PER...</td>\n",
       "      <td>[RT, @, CoutureiCON, :, I, hope, that, everyon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[i, wish, i, was, goin, to, the, concert, at, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-DATE, I-DATE, O, O,...</td>\n",
       "      <td>[Needs, a, concert, asap, ., ., ., ., sept, 9t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>[O, O, O, O, O, B-CARDINAL, O, O, O, O, O, O, ...</td>\n",
       "      <td>[I, 'm, sittin, here, listenin, 2, *, secret, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>[B-PERSON, O, O, O, B-GPE, B-TIME, O, O, O, O,...</td>\n",
       "      <td>[Bree, 's, heading, to, maryland, tonight, for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>[B-PERSON, I-PERSON, O, O, O, O, O, O, O]</td>\n",
       "      <td>[Jonny, Lang, concert, ,, anyone, else, here, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ners  \\\n",
       "0   [O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...   \n",
       "1   [O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...   \n",
       "2   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3   [O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...   \n",
       "4              [O, B-TIME, O, O, O, O, O, O, O, O, O]   \n",
       "5   [O, O, O, O, B-WORK_OF_ART, I-WORK_OF_ART, I-W...   \n",
       "6   [O, B-ORDINAL, O, O, O, O, O, O, O, O, O, O, O...   \n",
       "7   [O, B-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_AR...   \n",
       "8                  [O, B-PERSON, O, O, O, O, O, O, O]   \n",
       "9   [O, O, O, O, O, O, O, O, O, O, B-PERSON, O, O,...   \n",
       "10  [O, B-PERSON, O, O, O, O, O, O, O, O, O, O, B-...   \n",
       "11  [O, O, O, O, O, O, O, O, O, O, O, B-PERSON, O,...   \n",
       "12   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "13  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "14  [O, O, B-PERSON, O, O, O, O, O, O, O, O, B-PER...   \n",
       "15   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "16  [O, O, O, O, O, O, O, O, B-DATE, I-DATE, O, O,...   \n",
       "17  [O, O, O, O, O, B-CARDINAL, O, O, O, O, O, O, ...   \n",
       "18  [B-PERSON, O, O, O, B-GPE, B-TIME, O, O, O, O,...   \n",
       "19          [B-PERSON, I-PERSON, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                               tokens  \n",
       "0   [@, herRoyalStarnes, I, just, thought, of, the...  \n",
       "1   [Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...  \n",
       "2   [@, beccalexis, sup, Bee, ?, How, 'd, the, sho...  \n",
       "3   [RT, @, BoomKack, :, Janet, was, at, Lady, Gag...  \n",
       "4   [Concert, tonight, at, the, bellyup, !, The, g...  \n",
       "5   [They, Played, #FLEX, @, The, Jigga, Concert, ...  \n",
       "6   [My, First, Concert, ., .., Then, I, 'm, seein...  \n",
       "7   [In, The, Library, With, @, NickAustinG, ., .....  \n",
       "8   [@, RockStarRenRen, lol, is, we, going, to, th...  \n",
       "9   [Sooo, go, b4, u, wet, ur, self, @, ANGELicNES...  \n",
       "10  [@, Magpiez, uhm, who, in, their, right, mind,...  \n",
       "11  [awwww, :), RT, @_, tierra, :, How, cute, !, R...  \n",
       "12  [@, arinicolelife, are, u, going, to, the, dri...  \n",
       "13  [@, Britt_Garrison, jus, sent, me, some, audio...  \n",
       "14  [RT, @, CoutureiCON, :, I, hope, that, everyon...  \n",
       "15  [i, wish, i, was, goin, to, the, concert, at, ...  \n",
       "16  [Needs, a, concert, asap, ., ., ., ., sept, 9t...  \n",
       "17  [I, 'm, sittin, here, listenin, 2, *, secret, ...  \n",
       "18  [Bree, 's, heading, to, maryland, tonight, for...  \n",
       "19  [Jonny, Lang, concert, ,, anyone, else, here, ...  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at ner and tokens together. I'll use any 'FAC', 'GEP' or 'LOC' NER tags as the location.\n",
    "df_pd[['ners', 'tokens']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ners = ['FAC', 'GPE', 'LOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the tokens that are tagged with our target NERs into a cohesive location string\n",
    "locations = []\n",
    "for ners, tokens in zip(df_pd['ners'], df_pd['tokens']):\n",
    "    location = []\n",
    "    for ner, token in zip(ners, tokens):\n",
    "        if any(target_ner in ner for target_ner in target_ners):\n",
    "            location.append(token)\n",
    "    location = \" \".join(location)\n",
    "    locations.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding our locations to the pandas dataframe\n",
    "df_pd['where'] = locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>when</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>entities</th>\n",
       "      <th>ners</th>\n",
       "      <th>tokens</th>\n",
       "      <th>who</th>\n",
       "      <th>where</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@herRoyalStarnes I just thought of the history...</td>\n",
       "      <td>85691996</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive, positive]</td>\n",
       "      <td>[bmw]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...</td>\n",
       "      <td>[@, herRoyalStarnes, I, just, thought, of, the...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Y is me @RandiICandy, @EpitomeOfADiva, and Lei...</td>\n",
       "      <td>85691996</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[RandiICandy, EpitomeOfADiva, Leila Bunny, Mar...</td>\n",
       "      <td>[O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...</td>\n",
       "      <td>[Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...</td>\n",
       "      <td>None</td>\n",
       "      <td>EpitomeOfADiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@beccalexis sup Bee? How'd the shoot go? Will ...</td>\n",
       "      <td>25611870</td>\n",
       "      <td>None</td>\n",
       "      <td>[negative, negative, negative]</td>\n",
       "      <td>[tonight]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[@, beccalexis, sup, Bee, ?, How, 'd, the, sho...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @BoomKack: Janet was at Lady Gaga concert t...</td>\n",
       "      <td>25611870</td>\n",
       "      <td>None</td>\n",
       "      <td>[negative, positive]</td>\n",
       "      <td>[BoomKack, Janet, Gaga, tonight]</td>\n",
       "      <td>[O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...</td>\n",
       "      <td>[RT, @, BoomKack, :, Janet, was, at, Lady, Gag...</td>\n",
       "      <td>None</td>\n",
       "      <td>BoomKack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Concert tonight at the bellyup! The grouch&amp; mr...</td>\n",
       "      <td>30387809</td>\n",
       "      <td>None</td>\n",
       "      <td>[negative, positive]</td>\n",
       "      <td>[tonight]</td>\n",
       "      <td>[O, B-TIME, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[Concert, tonight, at, the, bellyup, !, The, g...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>They Played #FLEX @ The Jigga Concert... And #...</td>\n",
       "      <td>71702459</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive, negative]</td>\n",
       "      <td>[The Jigga Concert]</td>\n",
       "      <td>[O, O, O, O, B-WORK_OF_ART, I-WORK_OF_ART, I-W...</td>\n",
       "      <td>[They, Played, #FLEX, @, The, Jigga, Concert, ...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>My First Concert... Then I'm seeing one of the...</td>\n",
       "      <td>71702459</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive, negative]</td>\n",
       "      <td>[First]</td>\n",
       "      <td>[O, B-ORDINAL, O, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[My, First, Concert, ., .., Then, I, 'm, seein...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>In The Library With @NickAustinG... He Tryin T...</td>\n",
       "      <td>71702459</td>\n",
       "      <td>None</td>\n",
       "      <td>[negative, negative, negative]</td>\n",
       "      <td>[The Library With @NickAustinG]</td>\n",
       "      <td>[O, B-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_AR...</td>\n",
       "      <td>[In, The, Library, With, @, NickAustinG, ., .....</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>@RockStarRenRen lol is we going to this concert</td>\n",
       "      <td>49483366</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[RockStarRenRen]</td>\n",
       "      <td>[O, B-PERSON, O, O, O, O, O, O, O]</td>\n",
       "      <td>[@, RockStarRenRen, lol, is, we, going, to, th...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Sooo go b4 u wet ur self  @ANGELicNES: Hhuuuuh...</td>\n",
       "      <td>28528232</td>\n",
       "      <td>None</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[Hhuuuuhh, Jayz, SongzYuuup]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PERSON, O, O,...</td>\n",
       "      <td>[Sooo, go, b4, u, wet, ur, self, @, ANGELicNES...</td>\n",
       "      <td>None</td>\n",
       "      <td>SongzYuuup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   user_id  when  \\\n",
       "0  @herRoyalStarnes I just thought of the history...  85691996  None   \n",
       "1  Y is me @RandiICandy, @EpitomeOfADiva, and Lei...  85691996  None   \n",
       "2  @beccalexis sup Bee? How'd the shoot go? Will ...  25611870  None   \n",
       "3  RT @BoomKack: Janet was at Lady Gaga concert t...  25611870  None   \n",
       "4  Concert tonight at the bellyup! The grouch& mr...  30387809  None   \n",
       "5  They Played #FLEX @ The Jigga Concert... And #...  71702459  None   \n",
       "6  My First Concert... Then I'm seeing one of the...  71702459  None   \n",
       "7  In The Library With @NickAustinG... He Tryin T...  71702459  None   \n",
       "8    @RockStarRenRen lol is we going to this concert  49483366  None   \n",
       "9  Sooo go b4 u wet ur self  @ANGELicNES: Hhuuuuh...  28528232  None   \n",
       "\n",
       "                       sentiments  \\\n",
       "0            [positive, positive]   \n",
       "1                      [positive]   \n",
       "2  [negative, negative, negative]   \n",
       "3            [negative, positive]   \n",
       "4            [negative, positive]   \n",
       "5            [positive, negative]   \n",
       "6            [positive, negative]   \n",
       "7  [negative, negative, negative]   \n",
       "8                      [positive]   \n",
       "9                      [positive]   \n",
       "\n",
       "                                            entities  \\\n",
       "0                                              [bmw]   \n",
       "1  [RandiICandy, EpitomeOfADiva, Leila Bunny, Mar...   \n",
       "2                                          [tonight]   \n",
       "3                   [BoomKack, Janet, Gaga, tonight]   \n",
       "4                                          [tonight]   \n",
       "5                                [The Jigga Concert]   \n",
       "6                                            [First]   \n",
       "7                    [The Library With @NickAustinG]   \n",
       "8                                   [RockStarRenRen]   \n",
       "9                       [Hhuuuuhh, Jayz, SongzYuuup]   \n",
       "\n",
       "                                                ners  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...   \n",
       "1  [O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...   \n",
       "4             [O, B-TIME, O, O, O, O, O, O, O, O, O]   \n",
       "5  [O, O, O, O, B-WORK_OF_ART, I-WORK_OF_ART, I-W...   \n",
       "6  [O, B-ORDINAL, O, O, O, O, O, O, O, O, O, O, O...   \n",
       "7  [O, B-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_AR...   \n",
       "8                 [O, B-PERSON, O, O, O, O, O, O, O]   \n",
       "9  [O, O, O, O, O, O, O, O, O, O, B-PERSON, O, O,...   \n",
       "\n",
       "                                              tokens   who           where  \n",
       "0  [@, herRoyalStarnes, I, just, thought, of, the...  None                  \n",
       "1  [Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...  None  EpitomeOfADiva  \n",
       "2  [@, beccalexis, sup, Bee, ?, How, 'd, the, sho...  None                  \n",
       "3  [RT, @, BoomKack, :, Janet, was, at, Lady, Gag...  None        BoomKack  \n",
       "4  [Concert, tonight, at, the, bellyup, !, The, g...  None                  \n",
       "5  [They, Played, #FLEX, @, The, Jigga, Concert, ...  None                  \n",
       "6  [My, First, Concert, ., .., Then, I, 'm, seein...  None                  \n",
       "7  [In, The, Library, With, @, NickAustinG, ., .....  None                  \n",
       "8  [@, RockStarRenRen, lol, is, we, going, to, th...  None                  \n",
       "9  [Sooo, go, b4, u, wet, ur, self, @, ANGELicNES...  None      SongzYuuup  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment\n",
    "\n",
    "I'm curious about the differences in results from some of the different sentiment algorithms, but for now, we'll just go with the twitter-based sentiment analysis pretrained pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the sentiment readings for each row: +1 for positive, -1 for negative, then sum\n",
    "df_pd['sentiments'] = [sum([1 if s == 'positive' else -1 if s == 'negative' else 0 for s in s_list]) \n",
    "                             for s_list in df_pd['sentiments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>when</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>entities</th>\n",
       "      <th>ners</th>\n",
       "      <th>tokens</th>\n",
       "      <th>who</th>\n",
       "      <th>where</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@herRoyalStarnes I just thought of the history...</td>\n",
       "      <td>85691996</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>[bmw]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...</td>\n",
       "      <td>[@, herRoyalStarnes, I, just, thought, of, the...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Y is me @RandiICandy, @EpitomeOfADiva, and Lei...</td>\n",
       "      <td>85691996</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>[RandiICandy, EpitomeOfADiva, Leila Bunny, Mar...</td>\n",
       "      <td>[O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...</td>\n",
       "      <td>[Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...</td>\n",
       "      <td>None</td>\n",
       "      <td>EpitomeOfADiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@beccalexis sup Bee? How'd the shoot go? Will ...</td>\n",
       "      <td>25611870</td>\n",
       "      <td>None</td>\n",
       "      <td>-3</td>\n",
       "      <td>[tonight]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[@, beccalexis, sup, Bee, ?, How, 'd, the, sho...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @BoomKack: Janet was at Lady Gaga concert t...</td>\n",
       "      <td>25611870</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[BoomKack, Janet, Gaga, tonight]</td>\n",
       "      <td>[O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...</td>\n",
       "      <td>[RT, @, BoomKack, :, Janet, was, at, Lady, Gag...</td>\n",
       "      <td>None</td>\n",
       "      <td>BoomKack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Concert tonight at the bellyup! The grouch&amp; mr...</td>\n",
       "      <td>30387809</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[tonight]</td>\n",
       "      <td>[O, B-TIME, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[Concert, tonight, at, the, bellyup, !, The, g...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   user_id  when  \\\n",
       "0  @herRoyalStarnes I just thought of the history...  85691996  None   \n",
       "1  Y is me @RandiICandy, @EpitomeOfADiva, and Lei...  85691996  None   \n",
       "2  @beccalexis sup Bee? How'd the shoot go? Will ...  25611870  None   \n",
       "3  RT @BoomKack: Janet was at Lady Gaga concert t...  25611870  None   \n",
       "4  Concert tonight at the bellyup! The grouch& mr...  30387809  None   \n",
       "\n",
       "   sentiments                                           entities  \\\n",
       "0           2                                              [bmw]   \n",
       "1           1  [RandiICandy, EpitomeOfADiva, Leila Bunny, Mar...   \n",
       "2          -3                                          [tonight]   \n",
       "3           0                   [BoomKack, Janet, Gaga, tonight]   \n",
       "4           0                                          [tonight]   \n",
       "\n",
       "                                                ners  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...   \n",
       "1  [O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...   \n",
       "4             [O, B-TIME, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                              tokens   who           where  \n",
       "0  [@, herRoyalStarnes, I, just, thought, of, the...  None                  \n",
       "1  [Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...  None  EpitomeOfADiva  \n",
       "2  [@, beccalexis, sup, Bee, ?, How, 'd, the, sho...  None                  \n",
       "3  [RT, @, BoomKack, :, Janet, was, at, Lady, Gag...  None        BoomKack  \n",
       "4  [Concert, tonight, at, the, bellyup, !, The, g...  None                  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sentiment numbers to strings\n",
    "df_pd['sentiment'] = ['positive' if s > 0 else 'neutral' if s==0 else 'negative' for s in df_pd['sentiments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>when</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>entities</th>\n",
       "      <th>ners</th>\n",
       "      <th>tokens</th>\n",
       "      <th>who</th>\n",
       "      <th>where</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@herRoyalStarnes I just thought of the history...</td>\n",
       "      <td>85691996</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>[bmw]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...</td>\n",
       "      <td>[@, herRoyalStarnes, I, just, thought, of, the...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Y is me @RandiICandy, @EpitomeOfADiva, and Lei...</td>\n",
       "      <td>85691996</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>[RandiICandy, EpitomeOfADiva, Leila Bunny, Mar...</td>\n",
       "      <td>[O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...</td>\n",
       "      <td>[Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...</td>\n",
       "      <td>None</td>\n",
       "      <td>EpitomeOfADiva</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@beccalexis sup Bee? How'd the shoot go? Will ...</td>\n",
       "      <td>25611870</td>\n",
       "      <td>None</td>\n",
       "      <td>-3</td>\n",
       "      <td>[tonight]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[@, beccalexis, sup, Bee, ?, How, 'd, the, sho...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @BoomKack: Janet was at Lady Gaga concert t...</td>\n",
       "      <td>25611870</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[BoomKack, Janet, Gaga, tonight]</td>\n",
       "      <td>[O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...</td>\n",
       "      <td>[RT, @, BoomKack, :, Janet, was, at, Lady, Gag...</td>\n",
       "      <td>None</td>\n",
       "      <td>BoomKack</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Concert tonight at the bellyup! The grouch&amp; mr...</td>\n",
       "      <td>30387809</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[tonight]</td>\n",
       "      <td>[O, B-TIME, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[Concert, tonight, at, the, bellyup, !, The, g...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   user_id  when  \\\n",
       "0  @herRoyalStarnes I just thought of the history...  85691996  None   \n",
       "1  Y is me @RandiICandy, @EpitomeOfADiva, and Lei...  85691996  None   \n",
       "2  @beccalexis sup Bee? How'd the shoot go? Will ...  25611870  None   \n",
       "3  RT @BoomKack: Janet was at Lady Gaga concert t...  25611870  None   \n",
       "4  Concert tonight at the bellyup! The grouch& mr...  30387809  None   \n",
       "\n",
       "   sentiments                                           entities  \\\n",
       "0           2                                              [bmw]   \n",
       "1           1  [RandiICandy, EpitomeOfADiva, Leila Bunny, Mar...   \n",
       "2          -3                                          [tonight]   \n",
       "3           0                   [BoomKack, Janet, Gaga, tonight]   \n",
       "4           0                                          [tonight]   \n",
       "\n",
       "                                                ners  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...   \n",
       "1  [O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...   \n",
       "4             [O, B-TIME, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                              tokens   who           where  \\\n",
       "0  [@, herRoyalStarnes, I, just, thought, of, the...  None                   \n",
       "1  [Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...  None  EpitomeOfADiva   \n",
       "2  [@, beccalexis, sup, Bee, ?, How, 'd, the, sho...  None                   \n",
       "3  [RT, @, BoomKack, :, Janet, was, at, Lady, Gag...  None        BoomKack   \n",
       "4  [Concert, tonight, at, the, bellyup, !, The, g...  None                   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  negative  \n",
       "3   neutral  \n",
       "4   neutral  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audience\n",
    "\n",
    "I'll add the audience column.\n",
    "\n",
    "**Future: perhaps use the NER to determine the subject (but not the performer) or POS?\n",
    "\n",
    "Unfortunately, my attempt to use the POS tagger didn't work for today.\n",
    "\n",
    "I'm going with the basic solution - contains I or we, then the audience is the tweeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tagger = PerceptronApproach() \\\n",
    "#     .setInputCols([\"token\", \"document\"]) \\\n",
    "#     .setOutputCol(\"pos\") \\\n",
    "#     .setNIterations(5)\\\n",
    "#     .fit() # I'm not sure where to get the training data set for this....\n",
    "\n",
    "# finisher = finisher = Finisher() \\\n",
    "#      .setInputCols(['pos']) \\\n",
    "#      .setCleanAnnotations(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline()\\\n",
    "#                .setStages([\n",
    "#                     documentAssembler,\n",
    "#                     tokenizer,\n",
    "#                     pos_tagger,\n",
    "#                     finisher\n",
    "#                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.transform(df_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Future: perhaps use the NER to determine the subject (but not the performer) or POS?\n",
    "\n",
    "Unfortunately, my attempt to use the POS tagger didn't work for today.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tagger = PerceptronApproach() \\\n",
    "#     .setInputCols([\"token\", \"document\"]) \\\n",
    "#     .setOutputCol(\"pos\") \\\n",
    "#     .setNIterations(5)\\\n",
    "#     .fit() # I'm not sure where to get the training data set for this....\n",
    "\n",
    "# finisher = finisher = Finisher() \\\n",
    "#      .setInputCols(['pos']) \\\n",
    "#      .setCleanAnnotations(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline()\\\n",
    "#                .setStages([\n",
    "#                     documentAssembler,\n",
    "#                     tokenizer,\n",
    "#                     pos_tagger,\n",
    "#                     finisher\n",
    "#                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.transform(df_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So going with a simple solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_tokens_list = []\n",
    "for token_list in df_pd['tokens']:\n",
    "    lower_tokens_list.append([token.lower() for token in token_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd['audience'] = [u if ('i' in t or 'we' in t) \n",
    "                     else None \n",
    "                     for u, t in zip(df_pd['user_id'], lower_tokens_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>when</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>entities</th>\n",
       "      <th>ners</th>\n",
       "      <th>tokens</th>\n",
       "      <th>who</th>\n",
       "      <th>where</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>audience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@herRoyalStarnes I just thought of the history...</td>\n",
       "      <td>85691996</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>[bmw]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...</td>\n",
       "      <td>[@, herRoyalStarnes, I, just, thought, of, the...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td>85691996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Y is me @RandiICandy, @EpitomeOfADiva, and Lei...</td>\n",
       "      <td>85691996</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>[RandiICandy, EpitomeOfADiva, Leila Bunny, Mar...</td>\n",
       "      <td>[O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...</td>\n",
       "      <td>[Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...</td>\n",
       "      <td>None</td>\n",
       "      <td>EpitomeOfADiva</td>\n",
       "      <td>positive</td>\n",
       "      <td>85691996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@beccalexis sup Bee? How'd the shoot go? Will ...</td>\n",
       "      <td>25611870</td>\n",
       "      <td>None</td>\n",
       "      <td>-3</td>\n",
       "      <td>[tonight]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[@, beccalexis, sup, Bee, ?, How, 'd, the, sho...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @BoomKack: Janet was at Lady Gaga concert t...</td>\n",
       "      <td>25611870</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[BoomKack, Janet, Gaga, tonight]</td>\n",
       "      <td>[O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...</td>\n",
       "      <td>[RT, @, BoomKack, :, Janet, was, at, Lady, Gag...</td>\n",
       "      <td>None</td>\n",
       "      <td>BoomKack</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Concert tonight at the bellyup! The grouch&amp; mr...</td>\n",
       "      <td>30387809</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[tonight]</td>\n",
       "      <td>[O, B-TIME, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[Concert, tonight, at, the, bellyup, !, The, g...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   user_id  when  \\\n",
       "0  @herRoyalStarnes I just thought of the history...  85691996  None   \n",
       "1  Y is me @RandiICandy, @EpitomeOfADiva, and Lei...  85691996  None   \n",
       "2  @beccalexis sup Bee? How'd the shoot go? Will ...  25611870  None   \n",
       "3  RT @BoomKack: Janet was at Lady Gaga concert t...  25611870  None   \n",
       "4  Concert tonight at the bellyup! The grouch& mr...  30387809  None   \n",
       "\n",
       "   sentiments                                           entities  \\\n",
       "0           2                                              [bmw]   \n",
       "1           1  [RandiICandy, EpitomeOfADiva, Leila Bunny, Mar...   \n",
       "2          -3                                          [tonight]   \n",
       "3           0                   [BoomKack, Janet, Gaga, tonight]   \n",
       "4           0                                          [tonight]   \n",
       "\n",
       "                                                ners  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...   \n",
       "1  [O, O, O, O, B-ORG, O, O, B-FAC, O, O, B-PERSO...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, B-FAC, O, B-PERSON, O, O, O, B-PERSON, ...   \n",
       "4             [O, B-TIME, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                              tokens   who           where  \\\n",
       "0  [@, herRoyalStarnes, I, just, thought, of, the...  None                   \n",
       "1  [Y, is, me, @, RandiICandy, ,, @, EpitomeOfADi...  None  EpitomeOfADiva   \n",
       "2  [@, beccalexis, sup, Bee, ?, How, 'd, the, sho...  None                   \n",
       "3  [RT, @, BoomKack, :, Janet, was, at, Lady, Gag...  None        BoomKack   \n",
       "4  [Concert, tonight, at, the, bellyup, !, The, g...  None                   \n",
       "\n",
       "  sentiment    audience  \n",
       "0  positive  85691996.0  \n",
       "1  positive  85691996.0  \n",
       "2  negative         NaN  \n",
       "3   neutral         NaN  \n",
       "4   neutral         NaN  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = df_pd[['text', 'who', 'when', 'where', 'audience', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>who</th>\n",
       "      <th>when</th>\n",
       "      <th>where</th>\n",
       "      <th>audience</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@herRoyalStarnes I just thought of the history...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>85691996.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Y is me @RandiICandy, @EpitomeOfADiva, and Lei...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>EpitomeOfADiva</td>\n",
       "      <td>85691996.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@beccalexis sup Bee? How'd the shoot go? Will ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @BoomKack: Janet was at Lady Gaga concert t...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BoomKack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Concert tonight at the bellyup! The grouch&amp; mr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>They Played #FLEX @ The Jigga Concert... And #...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>My First Concert... Then I'm seeing one of the...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>71702459.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>In The Library With @NickAustinG... He Tryin T...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>71702459.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>@RockStarRenRen lol is we going to this concert</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>49483366.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Sooo go b4 u wet ur self  @ANGELicNES: Hhuuuuh...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SongzYuuup</td>\n",
       "      <td>28528232.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>@Magpiez uhm who in their right mind would pas...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>awwww :) RT @_tierra: How cute! RT @Djrayyadig...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>27446890.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>@arinicolelife are u going to the drizzy conce...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>@Britt_Garrison jus sent me some audio from th...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>27446890.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>RT @CoutureiCON: I hope that everyone is at th...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>27446890.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>i wish i was goin to the concert at state :( a...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>27446890.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Needs a concert asap....sept 9th come soon ple...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>I'm sittin here listenin 2 *secret lovers* n i...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>16608886.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Bree's heading to maryland tonight for another...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>maryland</td>\n",
       "      <td>5713172.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Jonny Lang concert, anyone else here? http://p...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>80s Babies Concert at Nokia Theater http://bit...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Bill Cosby - Cosby Joins Hancocks Birthday Con...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Whitney Houston - More Concert Woes For Housto...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Houston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Whitney Houston - Houston Sparks New Health Co...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Jason Derulo- Helps @ BET's \"SOS: Help for Hai...</td>\n",
       "      <td>[Jason Derulo]</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Whitney Houston - Houston Scraps New Zealand C...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>@Ms_CPerry Concert tickets are like 150 but fo...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>21963371.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>those who had concerts... Yall know me better ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>RT @QueenzChicka88: Finally Off!!!Gotta get ho...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>27274895.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>@juliembaby julz u going to the hov concert??</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text             who  when  \\\n",
       "0   @herRoyalStarnes I just thought of the history...            None  None   \n",
       "1   Y is me @RandiICandy, @EpitomeOfADiva, and Lei...            None  None   \n",
       "2   @beccalexis sup Bee? How'd the shoot go? Will ...            None  None   \n",
       "3   RT @BoomKack: Janet was at Lady Gaga concert t...            None  None   \n",
       "4   Concert tonight at the bellyup! The grouch& mr...            None  None   \n",
       "5   They Played #FLEX @ The Jigga Concert... And #...            None  None   \n",
       "6   My First Concert... Then I'm seeing one of the...            None  None   \n",
       "7   In The Library With @NickAustinG... He Tryin T...            None  None   \n",
       "8     @RockStarRenRen lol is we going to this concert            None  None   \n",
       "9   Sooo go b4 u wet ur self  @ANGELicNES: Hhuuuuh...            None  None   \n",
       "10  @Magpiez uhm who in their right mind would pas...            None  None   \n",
       "11  awwww :) RT @_tierra: How cute! RT @Djrayyadig...            None  None   \n",
       "12  @arinicolelife are u going to the drizzy conce...            None  None   \n",
       "13  @Britt_Garrison jus sent me some audio from th...            None  None   \n",
       "14  RT @CoutureiCON: I hope that everyone is at th...            None  None   \n",
       "15  i wish i was goin to the concert at state :( a...            None  None   \n",
       "16  Needs a concert asap....sept 9th come soon ple...            None  None   \n",
       "17  I'm sittin here listenin 2 *secret lovers* n i...            None  None   \n",
       "18  Bree's heading to maryland tonight for another...            None  None   \n",
       "19  Jonny Lang concert, anyone else here? http://p...            None  None   \n",
       "20  80s Babies Concert at Nokia Theater http://bit...            None  None   \n",
       "21  Bill Cosby - Cosby Joins Hancocks Birthday Con...            None  None   \n",
       "22  Whitney Houston - More Concert Woes For Housto...            None  None   \n",
       "23  Whitney Houston - Houston Sparks New Health Co...            None  None   \n",
       "24  Jason Derulo- Helps @ BET's \"SOS: Help for Hai...  [Jason Derulo]  None   \n",
       "25  Whitney Houston - Houston Scraps New Zealand C...            None  None   \n",
       "26  @Ms_CPerry Concert tickets are like 150 but fo...            None  None   \n",
       "27  those who had concerts... Yall know me better ...            None  None   \n",
       "28  RT @QueenzChicka88: Finally Off!!!Gotta get ho...            None  None   \n",
       "29      @juliembaby julz u going to the hov concert??            None  None   \n",
       "\n",
       "             where    audience sentiment  \n",
       "0                   85691996.0  positive  \n",
       "1   EpitomeOfADiva  85691996.0  positive  \n",
       "2                          NaN  negative  \n",
       "3         BoomKack         NaN   neutral  \n",
       "4                          NaN   neutral  \n",
       "5                          NaN   neutral  \n",
       "6                   71702459.0   neutral  \n",
       "7                   71702459.0  negative  \n",
       "8                   49483366.0  positive  \n",
       "9       SongzYuuup  28528232.0  positive  \n",
       "10                         NaN  positive  \n",
       "11                  27446890.0  negative  \n",
       "12                         NaN   neutral  \n",
       "13                  27446890.0  positive  \n",
       "14                  27446890.0   neutral  \n",
       "15                  27446890.0  positive  \n",
       "16                         NaN  negative  \n",
       "17                  16608886.0  negative  \n",
       "18        maryland   5713172.0  positive  \n",
       "19                         NaN  negative  \n",
       "20                         NaN  positive  \n",
       "21                         NaN   neutral  \n",
       "22         Houston         NaN  negative  \n",
       "23                         NaN  negative  \n",
       "24                         NaN  positive  \n",
       "25                         NaN  negative  \n",
       "26                  21963371.0  negative  \n",
       "27                         NaN  negative  \n",
       "28                  27274895.0   neutral  \n",
       "29                         NaN  positive  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd love to add more artists to my artist list, to make this more satisfying, and to figure out the issue with the date recognition and twitter sentiment detector. Another day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyspark-env)\n",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
