{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concert Tweet Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necesary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import count, when, col\n",
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import (Tokenizer, Normalizer,\n",
    "                                LemmatizerModel, StopWordsCleaner)\n",
    "from pyspark.ml import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the spark-NLP session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust show output format to pandas-like\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first go, there were 25k rows of null - where the schema did not match the data. I decided to do some quick cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_seps(in_file, out_file, sep):\n",
    "    \"\"\"removes newline characters that come before the line reaches four segments(3 separators)\n",
    "    and combines \"middle sections\" with extra separators into a single segment by removing the separators.\n",
    "    \n",
    "    Args:\n",
    "        in_file: path to read file\n",
    "        out_file: path to write file\n",
    "        sep: separator/delimitor\n",
    "    \"\"\"\n",
    "    n_chunks = 4\n",
    "    \n",
    "    with open(in_file, 'r') as rf:\n",
    "        with open(out_file, 'w') as wf:\n",
    "            while True:\n",
    "                line = rf.readline()\n",
    "                \n",
    "                # if end of file\n",
    "                if line == '':\n",
    "                    break\n",
    "                    \n",
    "                # if line has less than n_sep, strip the newline and add the next line\n",
    "                if len(line.split(sep)) < n_chunks:\n",
    "                    line = line.strip('\\n')\n",
    "                    line += rf.readline()\n",
    "                \n",
    "                wf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_extra_seps('../../data/test_set_tweets.txt',\n",
    "                      '../../data/test_set_tweets_clean.txt',\n",
    "                     '\\t')\n",
    "remove_extra_seps('../../data/training_set_tweets.txt',\n",
    "                      '../../data/training_set_tweets_clean.txt',\n",
    "                     '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the schema\n",
    "tweet_schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"t_id\", StringType(), True),\n",
    "    StructField(\"t_text\", StringType(), True),\n",
    "    StructField(\"t_dt\", TimestampType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test = spark.read.csv('../../data/test_set_tweets_clean.txt', \n",
    "                              sep='\\t',\n",
    "                              schema=tweet_schema,\n",
    "                              header=\"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_training = spark.read.csv('../../data/training_set_tweets_clean.txt', \n",
    "                                 sep=\"\\t\", \n",
    "                                 schema=tweet_schema,\n",
    "                                 header='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data is unlabeled for our task, these test/train splits are not particularly useful, but a vestige of the original data set and purpose. We'll combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets_test.union(tweets_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future: Consider reading the data as a single column and then parsing. Compare outcome / number of tweets retrieved to that with the csv reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Info About the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+-------------------+\n",
      "| user_id|       t_id|              t_text|               t_dt|\n",
      "+--------+-----------+--------------------+-------------------+\n",
      "|22077441|10538487904|Ok today I have t...|2010-03-15 17:35:58|\n",
      "|22077441|10536835844|I am glad I'm hav...|2010-03-15 16:53:44|\n",
      "|22077441|10536809086|Honestly I don't ...|2010-03-15 16:52:59|\n",
      "|22077441|10534149786|@LovelyJ_Janelle ...|2010-03-15 15:42:07|\n",
      "|22077441|10530203659|Sitting infront o...|2010-03-15 13:55:22|\n",
      "+--------+-----------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.select('*').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----+\n",
      "|user_id| t_id|t_text| t_dt|\n",
      "+-------+-----+------+-----+\n",
      "|  34555|34490| 34232|56489|\n",
      "+-------+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.select([count(when(col(c).isNull(), c)).alias(c) for c in \n",
    "        tweets.columns]).show()\n",
    "\n",
    "# print(\"\"\"+-------+-----+------+-----+\n",
    "# |user_id| t_id|t_text| t_dt|\n",
    "# +-------+-----+------+-----+\n",
    "# |  33289|33179| 32631|53805|\n",
    "# +-------+-----+------+-----+\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8884863"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()\n",
    "\n",
    "# print(8884863)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8850656\n"
     ]
    }
   ],
   "source": [
    "# tweets.distinct().count()\n",
    "print(8850656)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the time stamp can be parsed from the end of the tweet text for many of these \"null\" datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=22398295, t_id='10172355714', t_text='From my vantage point, when it comes to money, women tend to lack confidence in their ability to do the (cont) http://tl.gd/entj8\\t2010-03-08 00:00:00', t_dt=None),\n",
       " Row(user_id=22398295, t_id='10025719159', t_text='The best way to move a mountain is one stone at a time. Nothing is insurmountable if you take one step (cont) http://tl.gd/dt36c\\t2010-03-05 00:00:00', t_dt=None),\n",
       " Row(user_id=22398295, t_id='9828243702', t_text=\"I believe luck is preparation meeting opportunity. If you hadn't been prepared when the opportunity came (cont) http://tl.gd/cqt73\\t2010-03-01 00:00:00\", t_dt=None),\n",
       " Row(user_id=22398295, t_id='9542436310', t_text='Religion, philosophy, greeting cards, self-help booksâ€”they all tout the power of love. Being a chronic and (cont) http://tl.gd/b88fa\\t2010-02-23 00:00:00', t_dt=None),\n",
       " Row(user_id=22398295, t_id='9504909244', t_text=' A Leader is someone who nurtures others and allows them to progress and perform to their best ability. Whoever (cont) http://tl.gd/b1hlu\\t2010-02-22 00:00:00', t_dt=None)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.filter(col('t_dt').isNull()).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.withColumn('datetime', \n",
    "                           F.when(F.col('t_dt').isNull(), \n",
    "                                  F.to_date(F.substring('t_text', -19, 19)))\n",
    "                           .otherwise(F.col('t_dt'))\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.withColumn('t_text', \n",
    "                           F.when(F.col('t_dt').isNull(), \n",
    "                                  F.expr('substring(t_text, 1, length(t_text)-20)'))\n",
    "                           .otherwise(F.col('t_text'))\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.withColumn('t_dt', F.col('datetime')).drop('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as parquet and reload\n",
    "tweets.write.parquet('../../data/tweets.parquet')\n",
    "tweets = spark.read.parquet('../../data/tweets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----+\n",
      "|user_id| t_id|t_text| t_dt|\n",
      "+-------+-----+------+-----+\n",
      "|  34555|34490| 34232|54671|\n",
      "+-------+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.select([count(when(col(c).isNull(), c)).alias(c) for c in \n",
    "        tweets.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8884863"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.dropna(how='any', subset=['t_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=25513575, t_id='10334442280', t_text='', t_dt=None),\n",
       " Row(user_id=25513575, t_id='10333612651', t_text='', t_dt=None),\n",
       " Row(user_id=16198727, t_id='6899029209', t_text='This vid cracked me up! haha I w', t_dt=None),\n",
       " Row(user_id=20106865, t_id='10362030419', t_text=\"Ladies and gentlemen... come and join me.  It'\", t_dt=None),\n",
       " Row(user_id=20106865, t_id='10005503765', t_text='I am talking #Survivor RIGHT NOW in stickam', t_dt=None)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.filter(col('t_dt').isNull()).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly I could do some more/better data engineering here, but for this exercise, I'm going to move on, dropping any records with null values or t_text with empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.filter(~(tweets.t_text == \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8829912"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concert tweets - Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am deciding to focus on english tweets for now. (may add spanish, others in the future based on presence in the data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting up the pieces of my pipeline to extract text info from the tweets (we'll use a pretrained pipeline later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "     .setInputCol('t_text') \\\n",
    "     .setOutputCol('document')\n",
    "tokenizer = Tokenizer() \\\n",
    "     .setInputCols(['document']) \\\n",
    "     .setOutputCol('token')\n",
    "normalizer = Normalizer() \\\n",
    "     .setInputCols(['token']) \\\n",
    "     .setOutputCol('normalized') \\\n",
    "     .setLowercase(True)\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "     .setInputCols(['normalized']) \\\n",
    "     .setOutputCol('lemma')\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "     .setInputCols(['lemma']) \\\n",
    "     .setOutputCol('clean_lemma') \\\n",
    "     .setCaseSensitive(False) \\\n",
    "     .setStopWords(eng_stopwords)\n",
    "finisher = Finisher() \\\n",
    "     .setInputCols(['clean_lemma']) \\\n",
    "     .setCleanAnnotations(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline() \\\n",
    "     .setStages([\n",
    "           documentAssembler,\n",
    "           tokenizer,\n",
    "           normalizer,\n",
    "           lemmatizer,\n",
    "           stopwords_cleaner,\n",
    "           finisher\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pipeline.fit(tweets).transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 't_id',\n",
       " 't_text',\n",
       " 't_dt',\n",
       " 'document',\n",
       " 'token',\n",
       " 'normalized',\n",
       " 'lemma',\n",
       " 'clean_lemma',\n",
       " 'finished_clean_lemma']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Classifier: contains the word concert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "concert_tweets = tweets.withColumn('concert', F.array_contains('finished_clean_lemma', 'concert'))\n",
    "concert_tweets = concert_tweets.filter(concert_tweets['concert'] == 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(t_text=\"@herRoyalStarnes I just thought of the history broke down bmw's on bdays free concert tickets in the nose bleeds p (cont) http://tl.gd/4pp7k\"),\n",
       " Row(t_text='Y is me @RandiICandy, @EpitomeOfADiva, and Leila Bunny n here singing Mary J like we Mary J. We in concert yall buy a ticket yall.'),\n",
       " Row(t_text=\"@beccalexis sup Bee? How'd the shoot go? Will you be at the concert tonight?\")]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concert_tweets.select('t_text').take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12477\n"
     ]
    }
   ],
   "source": [
    "# concert_tweets.count()\n",
    "\n",
    "print(12477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 't_id',\n",
       " 't_text',\n",
       " 't_dt',\n",
       " 'document',\n",
       " 'token',\n",
       " 'normalized',\n",
       " 'lemma',\n",
       " 'clean_lemma',\n",
       " 'finished_clean_lemma',\n",
       " 'concert']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concert_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|t_text                                                                                                                                      |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|@herRoyalStarnes I just thought of the history broke down bmw's on bdays free concert tickets in the nose bleeds p (cont) http://tl.gd/4pp7k|\n",
      "|Y is me @RandiICandy, @EpitomeOfADiva, and Leila Bunny n here singing Mary J like we Mary J. We in concert yall buy a ticket yall.          |\n",
      "|@beccalexis sup Bee? How'd the shoot go? Will you be at the concert tonight?                                                                |\n",
      "|RT @BoomKack: Janet was at Lady Gaga concert tonight she is everything!!!!!! Can't touch her!                                               |\n",
      "|Concert tonight at the bellyup! The grouch& mr fab                                                                                          |\n",
      "|They Played #FLEX @ The Jigga Concert... And #MrHitDatHoe                                                                                   |\n",
      "|My First Concert... Then I'm seeing one of the best to ever do it                                                                           |\n",
      "|In The Library With @NickAustinG... He Tryin To Get On His Jigga Shit... Oh We Goin To The Concert Tonite                                   |\n",
      "|@RockStarRenRen lol is we going to this concert                                                                                             |\n",
      "|Sooo go b4 u wet ur self  @ANGELicNES: Hhuuuuhh I wanna go to this Jayz @SongzYuuup and Jeezy concert sooo bad                              |\n",
      "|@Magpiez uhm who in their right mind would pass up a John mayer concert?!?                                                                  |\n",
      "|awwww :) RT @_tierra: How cute! RT @Djrayyadig: I'm even more excited that I'm at the concert w/ @allantemitchell                           |\n",
      "|@arinicolelife are u going to the drizzy concert up there??? (State)                                                                        |\n",
      "|@Britt_Garrison jus sent me some audio from the concert lmao thats why i love my bf :)                                                      |\n",
      "|RT @CoutureiCON: I hope that everyone is at the Wharton for the FREE concert! BJ the Chicago Kid, Dom Kennedy and Keely!!                   |\n",
      "|i wish i was goin to the concert at state :( an having crack chicken later                                                                  |\n",
      "|Needs a concert asap....sept 9th come soon please.....                                                                                      |\n",
      "|I'm sittin here listenin 2 *secret lovers* n it made me lmao becuz I bet that was a long quiet ride hm frm d concert 4 d couples            |\n",
      "|Bree's heading to maryland tonight for another jonny lang concert. I've got the kids! #fb http://myloc.me/1nQui                             |\n",
      "|Jonny Lang concert, anyone else here? http://pic.gd/693682                                                                                  |\n",
      "|80s Babies Concert at Nokia Theater http://bit.ly/4wXmmO                                                                                    |\n",
      "|Bill Cosby - Cosby Joins Hancocks Birthday Concert Celebrations http://is.gd/9qlkh                                                          |\n",
      "|Whitney Houston - More Concert Woes For Houston http://is.gd/9a5zX                                                                          |\n",
      "|Whitney Houston - Houston Sparks New Health Concerns At Australia Concert http://is.gd/91Cs5                                                |\n",
      "|Jason Derulo- Helps @ BET's \"SOS: Help for Haiti\" Concert & Telethon http://is.gd/8GB7i                                                     |\n",
      "|Whitney Houston - Houston Scraps New Zealand Concert http://is.gd/8yxA3                                                                     |\n",
      "|@Ms_CPerry Concert tickets are like 150 but for the VIP is like 220-ish.. I fly southwest and plane ticket is like 250-ish...               |\n",
      "|those who had concerts... Yall know me better than that... #c'monson hahaha  http://myloc.me/1GDH7                                          |\n",
      "|RT @QueenzChicka88: Finally Off!!!Gotta get home so I can get ready to see my Boii\"HOVVVVVV\"2nite!!!:) -- U go to alllll his concerts! Lol  |\n",
      "|@juliembaby julz u going to the hov concert??                                                                                               |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "concert_tweets.select(\"t_text\").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Classifier: contains the word concert or similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "concert_plus = tweets.withColumn('concert', F.array_contains('finished_clean_lemma', 'concert'))\\\n",
    "                     .withColumn('tour', F.array_contains('finished_clean_lemma', 'tour'))\\\n",
    "                     .withColumn('gig', F.array_contains('finished_clean_lemma', 'gig'))\\\n",
    "                     .withColumn('show', F.array_contains('finished_clean_lemma', 'show'))\n",
    "concert_plus = concert_plus.withColumn('concert_like', col('concert')|col('tour')|col('gig'))\n",
    "concert_plus = concert_plus.filter(concert_plus.concert_like == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|t_text                                                                                                                                      |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|@Lauralu2u yeps I had curve than the tour.   Love my Droid                                                                                  |\n",
      "|@herRoyalStarnes I just thought of the history broke down bmw's on bdays free concert tickets in the nose bleeds p (cont) http://tl.gd/4pp7k|\n",
      "|Y is me @RandiICandy, @EpitomeOfADiva, and Leila Bunny n here singing Mary J like we Mary J. We in concert yall buy a ticket yall.          |\n",
      "|@joeymcintyre You've got to be a LITTLE bit silly on tour or you wouldn't be YOU! ;)                                                        |\n",
      "|Wrapped Product Development on samples, now headed to FedEx to snd to my client! Have fun on tour babe! Hope u like em! Wish I could twitpic|\n",
      "|@beccalexis sup Bee? How'd the shoot go? Will you be at the concert tonight?                                                                |\n",
      "|RT @BoomKack: Janet was at Lady Gaga concert tonight she is everything!!!!!! Can't touch her!                                               |\n",
      "|Up and at em..got booked for anotha gig in 10 days.. 3-5 Models, 3 looks a piece..need a intern/assistant BAD                               |\n",
      "|RT @DerrickSwerve: I Cant Wait 4 @Hollywood2BK and @HoffaBillz To Have These Hip Hop Groupies So I Can Smash All The Leftover Scraps On Tour|\n",
      "|Watching \"Shades of Brooklyn\" waiting for this pizza... #shoutouts to @HeartbreakHolly for his HBO gig, big bizne$$!!! Salute!              |\n",
      "|Concert tonight at the bellyup! The grouch& mr fab                                                                                          |\n",
      "|' My girl love me but fuck it my heart beats slow & right now the tour bus is lookin like a freak show '                                    |\n",
      "|@JCanMakeuFamous I'm wit it.. Paying gig?                                                                                                   |\n",
      "|@JaeBarz aww dnt trip.. Hardwork pays off.. You'll get ur gig.. Be ez on urself                                                             |\n",
      "|They Played #FLEX @ The Jigga Concert... And #MrHitDatHoe                                                                                   |\n",
      "|My First Concert... Then I'm seeing one of the best to ever do it                                                                           |\n",
      "|In The Library With @NickAustinG... He Tryin To Get On His Jigga Shit... Oh We Goin To The Concert Tonite                                   |\n",
      "|@RockStarRenRen lol is we going to this concert                                                                                             |\n",
      "|Sooo go b4 u wet ur self  @ANGELicNES: Hhuuuuhh I wanna go to this Jayz @SongzYuuup and Jeezy concert sooo bad                              |\n",
      "|@Magpiez uhm who in their right mind would pass up a John mayer concert?!?                                                                  |\n",
      "|awwww :) RT @_tierra: How cute! RT @Djrayyadig: I'm even more excited that I'm at the concert w/ @allantemitchell                           |\n",
      "|@arinicolelife are u going to the drizzy concert up there??? (State)                                                                        |\n",
      "|@Britt_Garrison jus sent me some audio from the concert lmao thats why i love my bf :)                                                      |\n",
      "|RT @CoutureiCON: I hope that everyone is at the Wharton for the FREE concert! BJ the Chicago Kid, Dom Kennedy and Keely!!                   |\n",
      "|i wish i was goin to the concert at state :( an having crack chicken later                                                                  |\n",
      "|You know you have a lot of music when you fill a 80gig external....                                                                         |\n",
      "|Needs a concert asap....sept 9th come soon please.....                                                                                      |\n",
      "|Nerves starting to set in..... Auditions for turning stone gig tomorrow....                                                                 |\n",
      "|Goooooh-jus :D had a fantastic day... Tour continuous tomorrow :) http://tweetphoto.com/13837678                                            |\n",
      "|@melmah  Hey, give me a shout.  I got a potential gig for you.                                                                              |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "concert_plus.select(\"t_text\").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this super small sample, it doesn't seem like these alternate words are adding a lot to our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future: maybe combination of show/tour/gig and musician/group name in addition to the concert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have labeled data, and I'm not sure the best technique for clustering text data in this situation. Or how we would evaluate which techniqes are doing the best job identifying our concert tweets, and whether they are worth the extra complexity/computational requirements.\n",
    "\n",
    "For now, I'm going to move on using the \"concert\" lemma classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyspark-env)\n",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
