{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concert Tweet Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necesary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import count, when, col\n",
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import (Tokenizer, Normalizer,\n",
    "                                LemmatizerModel, StopWordsCleaner, PerceptronApproach)\n",
    "from pyspark.ml import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the spark-NLP session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust show output format to pandas-like\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "# support converting pandas to spark\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first go, there were 25k rows of null - where the schema did not match the data. I decided to do some quick cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_seps(in_file, out_file, sep):\n",
    "    \"\"\"removes newline characters that come before the line reaches four segments(3 separators)\n",
    "    and combines \"middle sections\" with extra separators into a single segment by removing the separators.\n",
    "    \n",
    "    Args:\n",
    "        in_file: path to read file\n",
    "        out_file: path to write file\n",
    "        sep: separator/delimitor\n",
    "    \"\"\"\n",
    "    n_chunks = 4\n",
    "    \n",
    "    with open(in_file, 'r') as rf:\n",
    "        with open(out_file, 'w') as wf:\n",
    "            while True:\n",
    "                line = rf.readline()\n",
    "                \n",
    "                # if end of file\n",
    "                if line == '':\n",
    "                    break\n",
    "                    \n",
    "                # if line has less than n_sep, strip the newline and add the next line\n",
    "                if len(line.split(sep)) < n_chunks:\n",
    "                    line = line.strip('\\n')\n",
    "                    line += rf.readline()\n",
    "                \n",
    "                wf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_extra_seps('../../data/test_set_tweets.txt',\n",
    "                      '../../data/test_set_tweets_clean.txt',\n",
    "                     '\\t')\n",
    "remove_extra_seps('../../data/training_set_tweets.txt',\n",
    "                      '../../data/training_set_tweets_clean.txt',\n",
    "                     '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the schema\n",
    "tweet_schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"t_id\", StringType(), True),\n",
    "    StructField(\"t_text\", StringType(), True),\n",
    "    StructField(\"t_dt\", TimestampType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test = spark.read.csv('../../data/test_set_tweets_clean.txt', \n",
    "                              sep='\\t',\n",
    "                              schema=tweet_schema,\n",
    "                              header=\"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_training = spark.read.csv('../../data/training_set_tweets_clean.txt', \n",
    "                                 sep=\"\\t\", \n",
    "                                 schema=tweet_schema,\n",
    "                                 header='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data is unlabeled for our task, these test/train splits are not particularly useful, but a vestige of the original data set and purpose. We'll combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets_test.union(tweets_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future: Consider reading the data as a single column and then parsing. Compare outcome / number of tweets retrieved to that with the csv reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+-------------------+\n",
      "| user_id|       t_id|              t_text|               t_dt|\n",
      "+--------+-----------+--------------------+-------------------+\n",
      "|22077441|10538487904|Ok today I have t...|2010-03-15 17:35:58|\n",
      "|22077441|10536835844|I am glad I'm hav...|2010-03-15 16:53:44|\n",
      "|22077441|10536809086|Honestly I don't ...|2010-03-15 16:52:59|\n",
      "|22077441|10534149786|@LovelyJ_Janelle ...|2010-03-15 15:42:07|\n",
      "|22077441|10530203659|Sitting infront o...|2010-03-15 13:55:22|\n",
      "+--------+-----------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.select('*').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----+\n",
      "|user_id| t_id|t_text| t_dt|\n",
      "+-------+-----+------+-----+\n",
      "|  34555|34490| 34232|56489|\n",
      "+-------+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.select([count(when(col(c).isNull(), c)).alias(c) for c in \n",
    "        tweets.columns]).show()\n",
    "\n",
    "# print(\"\"\"+-------+-----+------+-----+\n",
    "# |user_id| t_id|t_text| t_dt|\n",
    "# +-------+-----+------+-----+\n",
    "# |  33289|33179| 32631|53805|\n",
    "# +-------+-----+------+-----+\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8884863"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()\n",
    "\n",
    "# print(8884863)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8850656\n"
     ]
    }
   ],
   "source": [
    "# tweets.distinct().count()\n",
    "print(8850656)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the time stamp can be parsed from the end of the tweet text for many of these \"null\" datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=22398295, t_id='10172355714', t_text='From my vantage point, when it comes to money, women tend to lack confidence in their ability to do the (cont) http://tl.gd/entj8\\t2010-03-08 00:00:00', t_dt=None),\n",
       " Row(user_id=22398295, t_id='10025719159', t_text='The best way to move a mountain is one stone at a time. Nothing is insurmountable if you take one step (cont) http://tl.gd/dt36c\\t2010-03-05 00:00:00', t_dt=None),\n",
       " Row(user_id=22398295, t_id='9828243702', t_text=\"I believe luck is preparation meeting opportunity. If you hadn't been prepared when the opportunity came (cont) http://tl.gd/cqt73\\t2010-03-01 00:00:00\", t_dt=None),\n",
       " Row(user_id=22398295, t_id='9542436310', t_text='Religion, philosophy, greeting cards, self-help books—they all tout the power of love. Being a chronic and (cont) http://tl.gd/b88fa\\t2010-02-23 00:00:00', t_dt=None),\n",
       " Row(user_id=22398295, t_id='9504909244', t_text=' A Leader is someone who nurtures others and allows them to progress and perform to their best ability. Whoever (cont) http://tl.gd/b1hlu\\t2010-02-22 00:00:00', t_dt=None)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.filter(col('t_dt').isNull()).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.withColumn('datetime', \n",
    "                           F.when(F.col('t_dt').isNull(), \n",
    "                                  F.to_date(F.substring('t_text', -19, 19)))\n",
    "                           .otherwise(F.col('t_dt'))\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.withColumn('t_text', \n",
    "                           F.when(F.col('t_dt').isNull(), \n",
    "                                  F.expr('substring(t_text, 1, length(t_text)-20)'))\n",
    "                           .otherwise(F.col('t_text'))\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.withColumn('t_dt', F.col('datetime')).drop('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as parquet and reload\n",
    "# tweets.write.parquet('../../data/tweets.parquet')\n",
    "tweets = spark.read.parquet('../../data/tweets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----+\n",
      "|user_id| t_id|t_text| t_dt|\n",
      "+-------+-----+------+-----+\n",
      "|  34555|34490| 34232|54671|\n",
      "+-------+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.select([count(when(col(c).isNull(), c)).alias(c) for c in \n",
    "        tweets.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8884863"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.dropna(how='any', subset=['t_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=25513575, t_id='10334442280', t_text='', t_dt=None),\n",
       " Row(user_id=25513575, t_id='10333612651', t_text='', t_dt=None),\n",
       " Row(user_id=16198727, t_id='6899029209', t_text='This vid cracked me up! haha I w', t_dt=None),\n",
       " Row(user_id=20106865, t_id='10362030419', t_text=\"Ladies and gentlemen... come and join me.  It'\", t_dt=None),\n",
       " Row(user_id=20106865, t_id='10005503765', t_text='I am talking #Survivor RIGHT NOW in stickam', t_dt=None)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.filter(col('t_dt').isNull()).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly I could do some more/better data engineering here, but for this exercise, I'm going to move on, dropping any records with null values or t_text with empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.filter(~(tweets.t_text == \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8829912"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concert tweets - Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am deciding to focus on english tweets for now. (may add spanish, others in the future based on presence in the data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting up the pieces of my pipeline to extract text info from the tweets (we'll use a pretrained pipeline later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "     .setInputCol('t_text') \\\n",
    "     .setOutputCol('document')\n",
    "tokenizer = Tokenizer() \\\n",
    "     .setInputCols(['document']) \\\n",
    "     .setOutputCol('token')\n",
    "normalizer = Normalizer() \\\n",
    "     .setInputCols(['token']) \\\n",
    "     .setOutputCol('normalized') \\\n",
    "     .setLowercase(True)\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "     .setInputCols(['normalized']) \\\n",
    "     .setOutputCol('lemma')\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "     .setInputCols(['lemma']) \\\n",
    "     .setOutputCol('clean_lemma') \\\n",
    "     .setCaseSensitive(False) \\\n",
    "     .setStopWords(eng_stopwords)\n",
    "finisher = Finisher() \\\n",
    "     .setInputCols(['clean_lemma']) \\\n",
    "     .setCleanAnnotations(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline() \\\n",
    "     .setStages([\n",
    "           documentAssembler,\n",
    "           tokenizer,\n",
    "           normalizer,\n",
    "           lemmatizer,\n",
    "           stopwords_cleaner,\n",
    "           finisher\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pipeline.fit(tweets).transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 't_id',\n",
       " 't_text',\n",
       " 't_dt',\n",
       " 'document',\n",
       " 'token',\n",
       " 'normalized',\n",
       " 'lemma',\n",
       " 'clean_lemma',\n",
       " 'finished_clean_lemma']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Classifier: contains the word concert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "concert_tweets = tweets.withColumn('concert', F.array_contains('finished_clean_lemma', 'concert'))\n",
    "concert_tweets = concert_tweets.filter(concert_tweets['concert'] == 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(t_text=\"@herRoyalStarnes I just thought of the history broke down bmw's on bdays free concert tickets in the nose bleeds p (cont) http://tl.gd/4pp7k\"),\n",
       " Row(t_text='Y is me @RandiICandy, @EpitomeOfADiva, and Leila Bunny n here singing Mary J like we Mary J. We in concert yall buy a ticket yall.'),\n",
       " Row(t_text=\"@beccalexis sup Bee? How'd the shoot go? Will you be at the concert tonight?\")]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concert_tweets.select('t_text').take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12477\n"
     ]
    }
   ],
   "source": [
    "# concert_tweets.count()\n",
    "\n",
    "print(12477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 't_id',\n",
       " 't_text',\n",
       " 't_dt',\n",
       " 'document',\n",
       " 'token',\n",
       " 'normalized',\n",
       " 'lemma',\n",
       " 'clean_lemma',\n",
       " 'finished_clean_lemma',\n",
       " 'concert']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concert_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|t_text                                                                                                                                      |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|@herRoyalStarnes I just thought of the history broke down bmw's on bdays free concert tickets in the nose bleeds p (cont) http://tl.gd/4pp7k|\n",
      "|Y is me @RandiICandy, @EpitomeOfADiva, and Leila Bunny n here singing Mary J like we Mary J. We in concert yall buy a ticket yall.          |\n",
      "|@beccalexis sup Bee? How'd the shoot go? Will you be at the concert tonight?                                                                |\n",
      "|RT @BoomKack: Janet was at Lady Gaga concert tonight she is everything!!!!!! Can't touch her!                                               |\n",
      "|Concert tonight at the bellyup! The grouch& mr fab                                                                                          |\n",
      "|They Played #FLEX @ The Jigga Concert... And #MrHitDatHoe                                                                                   |\n",
      "|My First Concert... Then I'm seeing one of the best to ever do it                                                                           |\n",
      "|In The Library With @NickAustinG... He Tryin To Get On His Jigga Shit... Oh We Goin To The Concert Tonite                                   |\n",
      "|@RockStarRenRen lol is we going to this concert                                                                                             |\n",
      "|Sooo go b4 u wet ur self  @ANGELicNES: Hhuuuuhh I wanna go to this Jayz @SongzYuuup and Jeezy concert sooo bad                              |\n",
      "|@Magpiez uhm who in their right mind would pass up a John mayer concert?!?                                                                  |\n",
      "|awwww :) RT @_tierra: How cute! RT @Djrayyadig: I'm even more excited that I'm at the concert w/ @allantemitchell                           |\n",
      "|@arinicolelife are u going to the drizzy concert up there??? (State)                                                                        |\n",
      "|@Britt_Garrison jus sent me some audio from the concert lmao thats why i love my bf :)                                                      |\n",
      "|RT @CoutureiCON: I hope that everyone is at the Wharton for the FREE concert! BJ the Chicago Kid, Dom Kennedy and Keely!!                   |\n",
      "|i wish i was goin to the concert at state :( an having crack chicken later                                                                  |\n",
      "|Needs a concert asap....sept 9th come soon please.....                                                                                      |\n",
      "|I'm sittin here listenin 2 *secret lovers* n it made me lmao becuz I bet that was a long quiet ride hm frm d concert 4 d couples            |\n",
      "|Bree's heading to maryland tonight for another jonny lang concert. I've got the kids! #fb http://myloc.me/1nQui                             |\n",
      "|Jonny Lang concert, anyone else here? http://pic.gd/693682                                                                                  |\n",
      "|80s Babies Concert at Nokia Theater http://bit.ly/4wXmmO                                                                                    |\n",
      "|Bill Cosby - Cosby Joins Hancocks Birthday Concert Celebrations http://is.gd/9qlkh                                                          |\n",
      "|Whitney Houston - More Concert Woes For Houston http://is.gd/9a5zX                                                                          |\n",
      "|Whitney Houston - Houston Sparks New Health Concerns At Australia Concert http://is.gd/91Cs5                                                |\n",
      "|Jason Derulo- Helps @ BET's \"SOS: Help for Haiti\" Concert & Telethon http://is.gd/8GB7i                                                     |\n",
      "|Whitney Houston - Houston Scraps New Zealand Concert http://is.gd/8yxA3                                                                     |\n",
      "|@Ms_CPerry Concert tickets are like 150 but for the VIP is like 220-ish.. I fly southwest and plane ticket is like 250-ish...               |\n",
      "|those who had concerts... Yall know me better than that... #c'monson hahaha  http://myloc.me/1GDH7                                          |\n",
      "|RT @QueenzChicka88: Finally Off!!!Gotta get home so I can get ready to see my Boii\"HOVVVVVV\"2nite!!!:) -- U go to alllll his concerts! Lol  |\n",
      "|@juliembaby julz u going to the hov concert??                                                                                               |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "concert_tweets.select(\"t_text\").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Classifier: contains the word concert or similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "concert_plus = tweets.withColumn('concert', F.array_contains('finished_clean_lemma', 'concert'))\\\n",
    "                     .withColumn('tour', F.array_contains('finished_clean_lemma', 'tour'))\\\n",
    "                     .withColumn('gig', F.array_contains('finished_clean_lemma', 'gig'))\\\n",
    "                     .withColumn('show', F.array_contains('finished_clean_lemma', 'show'))\n",
    "concert_plus = concert_plus.withColumn('concert_like', col('concert')|col('tour')|col('gig'))\n",
    "concert_plus = concert_plus.filter(concert_plus.concert_like == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|t_text                                                                                                                                      |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|@Lauralu2u yeps I had curve than the tour.   Love my Droid                                                                                  |\n",
      "|@herRoyalStarnes I just thought of the history broke down bmw's on bdays free concert tickets in the nose bleeds p (cont) http://tl.gd/4pp7k|\n",
      "|Y is me @RandiICandy, @EpitomeOfADiva, and Leila Bunny n here singing Mary J like we Mary J. We in concert yall buy a ticket yall.          |\n",
      "|@joeymcintyre You've got to be a LITTLE bit silly on tour or you wouldn't be YOU! ;)                                                        |\n",
      "|Wrapped Product Development on samples, now headed to FedEx to snd to my client! Have fun on tour babe! Hope u like em! Wish I could twitpic|\n",
      "|@beccalexis sup Bee? How'd the shoot go? Will you be at the concert tonight?                                                                |\n",
      "|RT @BoomKack: Janet was at Lady Gaga concert tonight she is everything!!!!!! Can't touch her!                                               |\n",
      "|Up and at em..got booked for anotha gig in 10 days.. 3-5 Models, 3 looks a piece..need a intern/assistant BAD                               |\n",
      "|RT @DerrickSwerve: I Cant Wait 4 @Hollywood2BK and @HoffaBillz To Have These Hip Hop Groupies So I Can Smash All The Leftover Scraps On Tour|\n",
      "|Watching \"Shades of Brooklyn\" waiting for this pizza... #shoutouts to @HeartbreakHolly for his HBO gig, big bizne$$!!! Salute!              |\n",
      "|Concert tonight at the bellyup! The grouch& mr fab                                                                                          |\n",
      "|' My girl love me but fuck it my heart beats slow & right now the tour bus is lookin like a freak show '                                    |\n",
      "|@JCanMakeuFamous I'm wit it.. Paying gig?                                                                                                   |\n",
      "|@JaeBarz aww dnt trip.. Hardwork pays off.. You'll get ur gig.. Be ez on urself                                                             |\n",
      "|They Played #FLEX @ The Jigga Concert... And #MrHitDatHoe                                                                                   |\n",
      "|My First Concert... Then I'm seeing one of the best to ever do it                                                                           |\n",
      "|In The Library With @NickAustinG... He Tryin To Get On His Jigga Shit... Oh We Goin To The Concert Tonite                                   |\n",
      "|@RockStarRenRen lol is we going to this concert                                                                                             |\n",
      "|Sooo go b4 u wet ur self  @ANGELicNES: Hhuuuuhh I wanna go to this Jayz @SongzYuuup and Jeezy concert sooo bad                              |\n",
      "|@Magpiez uhm who in their right mind would pass up a John mayer concert?!?                                                                  |\n",
      "|awwww :) RT @_tierra: How cute! RT @Djrayyadig: I'm even more excited that I'm at the concert w/ @allantemitchell                           |\n",
      "|@arinicolelife are u going to the drizzy concert up there??? (State)                                                                        |\n",
      "|@Britt_Garrison jus sent me some audio from the concert lmao thats why i love my bf :)                                                      |\n",
      "|RT @CoutureiCON: I hope that everyone is at the Wharton for the FREE concert! BJ the Chicago Kid, Dom Kennedy and Keely!!                   |\n",
      "|i wish i was goin to the concert at state :( an having crack chicken later                                                                  |\n",
      "|You know you have a lot of music when you fill a 80gig external....                                                                         |\n",
      "|Needs a concert asap....sept 9th come soon please.....                                                                                      |\n",
      "|Nerves starting to set in..... Auditions for turning stone gig tomorrow....                                                                 |\n",
      "|Goooooh-jus :D had a fantastic day... Tour continuous tomorrow :) http://tweetphoto.com/13837678                                            |\n",
      "|@melmah  Hey, give me a shout.  I got a potential gig for you.                                                                              |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "concert_plus.select(\"t_text\").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this super small sample, it doesn't seem like these alternate words are adding a lot to our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future: maybe combination of show/tour/gig and musician/group name in addition to the concert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have labeled data, and I'm not sure the best technique for clustering text data in this situation. Or how we would evaluate which techniqes are doing the best job identifying our concert tweets, and whether they are worth the extra complexity/computational requirements.\n",
    "\n",
    "For now, I'm going to move on using the \"concert\" lemma classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concert_tweets.select('user_id', 't_text', 't_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>user_id</th><th>t_text</th><th>t_dt</th></tr>\n",
       "<tr><td>85691996</td><td>@herRoyalStarnes ...</td><td>2010-01-22 10:17:15</td></tr>\n",
       "<tr><td>85691996</td><td>Y is me @RandiICa...</td><td>2010-01-15 16:22:28</td></tr>\n",
       "<tr><td>25611870</td><td>@beccalexis sup B...</td><td>2010-01-30 00:00:00</td></tr>\n",
       "<tr><td>25611870</td><td>RT @BoomKack: Jan...</td><td>2010-01-24 00:00:00</td></tr>\n",
       "<tr><td>30387809</td><td>Concert tonight a...</td><td>2009-12-09 15:06:12</td></tr>\n",
       "<tr><td>71702459</td><td>They Played #FLEX...</td><td>2010-02-22 19:59:44</td></tr>\n",
       "<tr><td>71702459</td><td>My First Concert....</td><td>2010-02-22 19:26:40</td></tr>\n",
       "<tr><td>71702459</td><td>In The Library Wi...</td><td>2010-02-22 11:32:56</td></tr>\n",
       "<tr><td>49483366</td><td>@RockStarRenRen l...</td><td>2009-07-30 11:56:06</td></tr>\n",
       "<tr><td>28528232</td><td>Sooo go b4 u wet ...</td><td>2010-01-13 16:37:44</td></tr>\n",
       "<tr><td>22542268</td><td>@Magpiez uhm who ...</td><td>2010-03-02 01:47:55</td></tr>\n",
       "<tr><td>27446890</td><td>awwww :) RT @_tie...</td><td>2010-03-14 18:24:28</td></tr>\n",
       "<tr><td>27446890</td><td>@arinicolelife ar...</td><td>2010-03-02 09:21:26</td></tr>\n",
       "<tr><td>27446890</td><td>@Britt_Garrison j...</td><td>2010-02-11 19:58:51</td></tr>\n",
       "<tr><td>27446890</td><td>RT @CoutureiCON: ...</td><td>2010-02-11 17:45:41</td></tr>\n",
       "<tr><td>27446890</td><td>i wish i was goin...</td><td>2010-02-11 16:21:15</td></tr>\n",
       "<tr><td>22408811</td><td>Needs a concert a...</td><td>2009-08-18 00:00:00</td></tr>\n",
       "<tr><td>16608886</td><td>I&#x27;m sittin here l...</td><td>2010-03-02 10:55:52</td></tr>\n",
       "<tr><td>5713172</td><td>Bree&#x27;s heading to...</td><td>2009-11-07 10:49:57</td></tr>\n",
       "<tr><td>5713172</td><td>Jonny Lang concer...</td><td>2009-11-05 18:48:41</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------+--------------------+-------------------+\n",
       "| user_id|              t_text|               t_dt|\n",
       "+--------+--------------------+-------------------+\n",
       "|85691996|@herRoyalStarnes ...|2010-01-22 10:17:15|\n",
       "|85691996|Y is me @RandiICa...|2010-01-15 16:22:28|\n",
       "|25611870|@beccalexis sup B...|2010-01-30 00:00:00|\n",
       "|25611870|RT @BoomKack: Jan...|2010-01-24 00:00:00|\n",
       "|30387809|Concert tonight a...|2009-12-09 15:06:12|\n",
       "|71702459|They Played #FLEX...|2010-02-22 19:59:44|\n",
       "|71702459|My First Concert....|2010-02-22 19:26:40|\n",
       "|71702459|In The Library Wi...|2010-02-22 11:32:56|\n",
       "|49483366|@RockStarRenRen l...|2009-07-30 11:56:06|\n",
       "|28528232|Sooo go b4 u wet ...|2010-01-13 16:37:44|\n",
       "|22542268|@Magpiez uhm who ...|2010-03-02 01:47:55|\n",
       "|27446890|awwww :) RT @_tie...|2010-03-14 18:24:28|\n",
       "|27446890|@arinicolelife ar...|2010-03-02 09:21:26|\n",
       "|27446890|@Britt_Garrison j...|2010-02-11 19:58:51|\n",
       "|27446890|RT @CoutureiCON: ...|2010-02-11 17:45:41|\n",
       "|27446890|i wish i was goin...|2010-02-11 16:21:15|\n",
       "|22408811|Needs a concert a...|2009-08-18 00:00:00|\n",
       "|16608886|I'm sittin here l...|2010-03-02 10:55:52|\n",
       "| 5713172|Bree's heading to...|2009-11-07 10:49:57|\n",
       "| 5713172|Jonny Lang concer...|2009-11-05 18:48:41|\n",
       "+--------+--------------------+-------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12444\n"
     ]
    }
   ],
   "source": [
    "# df.count()\n",
    "print(12444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-------------------+\n",
      "| user_id|              t_text|               t_dt|\n",
      "+--------+--------------------+-------------------+\n",
      "|85691996|@herRoyalStarnes ...|2010-01-22 10:17:15|\n",
      "+--------+--------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(withReplacement=None, fraction=0.01, seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.withColumnRenamed('t_text', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id', 'text', 't_dt']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=71702459, text='In The Library With @NickAustinG... He Tryin To Get On His Jigga Shit... Oh We Goin To The Concert Tonite', t_dt=datetime.datetime(2010, 2, 22, 11, 32, 56)),\n",
       " Row(user_id=49483366, text='@RockStarRenRen lol is we going to this concert', t_dt=datetime.datetime(2009, 7, 30, 11, 56, 6)),\n",
       " Row(user_id=19688989, text='@bizymare   My son lives in Kenosha, I\"m down there about a dozen times a year.    The concert was for the Kenosha area home schoolers.', t_dt=datetime.datetime(2009, 12, 11, 22, 16, 24)),\n",
       " Row(user_id=20019157, text='@itSHOWTIME how was the concert?', t_dt=datetime.datetime(2010, 1, 19, 0, 0)),\n",
       " Row(user_id=49477598, text=\"@audiobebop what time? I'm suppose to go to a concert tonight with Juda. uhh\", t_dt=datetime.datetime(2010, 1, 15, 9, 26, 7)),\n",
       " Row(user_id=33814590, text='@MizzDania How was the concert?', t_dt=datetime.datetime(2010, 1, 22, 0, 0)),\n",
       " Row(user_id=29299184, text='The A was poppin @S_C_ @SongzYuuup and jeezy held the concert down.. Back in tally 2 papers and 2 midterms due tues. # backtoboredom', t_dt=datetime.datetime(2010, 2, 28, 17, 31, 30)),\n",
       " Row(user_id=60822006, text='@melodyxxx LOL u ladies go hard! Are u guys going the kid cudi concert on Saturday?', t_dt=datetime.datetime(2009, 11, 23, 10, 5, 41)),\n",
       " Row(user_id=27474555, text=\"Look, I'm sorry about Chile and Haiti, but for real, do we need another benefit concert? COME ON! What about people here, in the USA?\", t_dt=datetime.datetime(2010, 2, 27, 8, 56, 55)),\n",
       " Row(user_id=24024339, text='U r!  had to get Fred cause he was doing a Radio One concert yesterday!  I start in Nov...and u know I got u!  In fact I want PAJAM to d ...', t_dt=datetime.datetime(2009, 10, 11, 7, 23, 33)),\n",
       " Row(user_id=14529852, text='Gearing up for The Decemberists concert tonight by listening to all of their music. T minus 6 hours until the doors open.', t_dt=datetime.datetime(2009, 8, 11, 12, 38, 36)),\n",
       " Row(user_id=44382895, text='Getting ready to leave for a concert of an old friends new boyfriend. Should be interesting!', t_dt=datetime.datetime(2010, 1, 16, 19, 20, 49)),\n",
       " Row(user_id=23347429, text=\"@DustinLuminate hey, when ya'll do concerts do u take your own lighting & sound with you?\", t_dt=datetime.datetime(2009, 8, 19, 22, 49, 53)),\n",
       " Row(user_id=23347429, text='Listening to some @JonasBrothers + getting ready for their concert.....19 more days!!!!!*******', t_dt=datetime.datetime(2009, 7, 10, 22, 58, 16)),\n",
       " Row(user_id=30614011, text=\"@chrisettefan No she's the headliner. The concert started @ 8 Lem was leaving the stage @ 8:14. The girl had 30mins. Chrissy rocked the...\", t_dt=datetime.datetime(2010, 3, 4, 7, 19, 50)),\n",
       " Row(user_id=38593112, text=\"@RecruitZero CONGRATS!! ..And, I'll have you know sir that concerts and nightspots provide wonderful networking opps. ::grr::\", t_dt=datetime.datetime(2009, 9, 12, 19, 7, 7)),\n",
       " Row(user_id=19325588, text='RT @Platinumstroke: @ibhappy  Plz RT! Pain2Power Foundation Benefit & Inspirational Concert in memory of (cont) http://tl.gd/8f6qv', t_dt=datetime.datetime(2010, 2, 11, 16, 34, 57)),\n",
       " Row(user_id=26809809, text='RT @LiveNation: 500th RT wins $100 CONCERT CASH! http://bit.ly/9o9vZt', t_dt=datetime.datetime(2010, 2, 19, 13, 55, 56)),\n",
       " Row(user_id=26809809, text=\"I can't wait to see NKOTB in concert @LiveNation with my $100 concert cash!!! http://bit.ly/cT4csz\", t_dt=datetime.datetime(2010, 1, 28, 14, 19, 8)),\n",
       " Row(user_id=26809809, text=\"I can't wait to see NKOTB in concert @LiveNation with my $100 concert cash!!http://bit.ly/cT4csz\", t_dt=datetime.datetime(2010, 1, 28, 14, 18, 30))]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who\n",
    "\n",
    "For the sake of time, I focused on pop and hip hop artists from 2009/2010 (data from wikipedia). This is extra tricky when tweeters use the artist handles (eg @JonasBrothers), again this is an area for future iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import artist list\n",
    "with open('../../data/musicians.txt', 'r') as f:\n",
    "     artists = f.read().splitlines()\n",
    "        \n",
    "artists = list(set(artists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explain_document_dl download started this may take some time.\n",
      "Approx size to download 167.3 MB\n",
      "[OK!]\n",
      "+--------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| user_id|                text|               t_dt|            document|            sentence|               token|             checked|               lemma|                stem|                 pos|          embeddings|                 ner|            entities|\n",
      "+--------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|71702459|In The Library Wi...|2010-02-22 11:32:56|[[document, 0, 10...|[[document, 0, 34...|[[token, 0, 1, In...|[[token, 0, 1, In...|[[token, 0, 1, In...|[[token, 0, 1, in...|[[pos, 0, 1, IN, ...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 3, 31, T...|\n",
      "+--------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = PretrainedPipeline(\"explain_document_dl\", lang=\"en\")\n",
    "\n",
    "annotation = pipeline.transform(sample)\n",
    "\n",
    "annotation.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+\n",
      "|result                                                 |\n",
      "+-------------------------------------------------------+\n",
      "|[The Library With @NickAustinG, The Concert Tonite]    |\n",
      "|[@RockStarRenRen]                                      |\n",
      "|[Kenosha, I\"m, Kenosha]                                |\n",
      "|[]                                                     |\n",
      "|[Juda]                                                 |\n",
      "|[@MizzDania]                                           |\n",
      "|[@S_C_ @SongzYuuup]                                    |\n",
      "|[]                                                     |\n",
      "|[I'm, Chile, Haiti, USA]                               |\n",
      "|[Fred, Radio One, PAJAM]                               |\n",
      "|[Decemberists]                                         |\n",
      "|[]                                                     |\n",
      "|[&]                                                    |\n",
      "|[@JonasBrothers +, !!!!!*******]                       |\n",
      "|[Lem, Chrissy]                                         |\n",
      "|[@RecruitZero, I'll]                                   |\n",
      "|[Pain2Power Foundation Benefit & Inspirational Concert]|\n",
      "|[]                                                     |\n",
      "|[NKOTB]                                                |\n",
      "|[NKOTB]                                                |\n",
      "+-------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotation.select(\"entities.result\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MF DOOM',\n",
       " 'Joe Budden',\n",
       " 'Project Pat',\n",
       " 'Jeremih',\n",
       " 'Lil Jon',\n",
       " 'Katy Perry',\n",
       " 'N.O.R.E.',\n",
       " 'Souls of Mischief',\n",
       " 'Akon',\n",
       " 'The Main',\n",
       " 'Redman',\n",
       " 'Famous Playaz',\n",
       " 'Pink',\n",
       " 'Mack 10',\n",
       " 'Stevie Stone',\n",
       " 'Cali Swag District',\n",
       " \"Ol' Dirty Bastard\",\n",
       " 'Livestock',\n",
       " 'Soap Nation',\n",
       " 'Soul Assassins',\n",
       " 'Young Money',\n",
       " 'U-God',\n",
       " 'Eminem',\n",
       " 'Crunk Chris',\n",
       " 'Kottonmouth Kings',\n",
       " 'Soulja Boy',\n",
       " 'David Guetta',\n",
       " 'Method Man & Redman',\n",
       " 'Nicki Minaj',\n",
       " 'The Alchemist',\n",
       " 'Dead Prez',\n",
       " 'DJ Drama',\n",
       " 'Drake',\n",
       " 'Tyga',\n",
       " 'B.o.B',\n",
       " 'Kris Allen',\n",
       " 'Chico DeBarge',\n",
       " 'Linkin Park',\n",
       " 'Kesha',\n",
       " 'Haystak',\n",
       " 'Bruno Mars',\n",
       " 'Justin Bieber',\n",
       " 'Skull Gang',\n",
       " 'Ray J',\n",
       " 'DJ Paul',\n",
       " 'Busta Rhymes',\n",
       " 'Sean Kingston',\n",
       " 'Insane Clown Posse',\n",
       " 'Skyzoo',\n",
       " 'Shinedown',\n",
       " 'Owl City',\n",
       " 'Kings of Leon',\n",
       " 'Timbaland',\n",
       " 'Maroon 5',\n",
       " 'Del the Funky Homosapien',\n",
       " 'Obie Trice',\n",
       " 'Playaz Circle',\n",
       " 'Beyoncé',\n",
       " 'Maino',\n",
       " 'Webstar',\n",
       " 'Eminem featuring Rihanna',\n",
       " 'Juvenile',\n",
       " 'Taio Cruz',\n",
       " 'Lil Wyte',\n",
       " 'Lady Antebellum',\n",
       " 'Birdman',\n",
       " 'OJ Da Juiceman',\n",
       " 'Sammie',\n",
       " 'Paramore',\n",
       " 'B-Real',\n",
       " 'Zion I',\n",
       " 'Kurupt',\n",
       " 'Shontelle',\n",
       " 'UGK',\n",
       " 'Lord Infamous, T-Rock & II Tone',\n",
       " 'Yukmouth',\n",
       " 'Swollen Members',\n",
       " 'will.i.am',\n",
       " 'Slim Thug',\n",
       " 'Gudda Gudda',\n",
       " 'Abilities',\n",
       " 'CRUNK23',\n",
       " 'Wale',\n",
       " 'Chipmunk',\n",
       " 'Ne-Yo',\n",
       " 'Kevin Rudolf',\n",
       " 'Kelly Clarkson',\n",
       " 'The Fray',\n",
       " 'The Cataracs',\n",
       " 'Jim Jones',\n",
       " 'Mos Def',\n",
       " 'The Script',\n",
       " 'O.S.T.R.',\n",
       " 'Plies',\n",
       " 'Rivers Cuomo',\n",
       " 'Royce da 5\\'9\"',\n",
       " 'Mariah Carey',\n",
       " 'Twiztid',\n",
       " 'DJ Quik',\n",
       " 'Hussein Fatal',\n",
       " 'Paul Wall',\n",
       " 'Daughtry',\n",
       " 'Sheek Louch',\n",
       " 'Freeway',\n",
       " 'New Boyz',\n",
       " 'La Coka Nostra',\n",
       " 'J Dilla',\n",
       " 'Q-Tip',\n",
       " 'Adam Lambert',\n",
       " 'Fast Life Yungstaz',\n",
       " 'NKOTB',\n",
       " 'T.I.',\n",
       " 'Lisa \"Left Eye\" Lopes',\n",
       " 'X-Raided',\n",
       " 'Mike Epps',\n",
       " 'Selena Gomez & the Scene',\n",
       " 'Lil Wayne',\n",
       " 'AZ',\n",
       " 'D-Block',\n",
       " 'Stoupe the Enemy of Mankind',\n",
       " 'Dr. Dre',\n",
       " 'Usher',\n",
       " 'Dev',\n",
       " 'Hurricane Chris',\n",
       " 'Krizz Kaliko',\n",
       " 'Felt',\n",
       " 'BlakRoc',\n",
       " 'Ace Hood',\n",
       " 'OneRepublic',\n",
       " 'Lady Gaga',\n",
       " 'The Sounds',\n",
       " 'Fabolous',\n",
       " \"Lil' Flip\",\n",
       " 'Ludacris',\n",
       " 'Eyedea',\n",
       " 'Taylor Swift',\n",
       " 'Boys Like Girls',\n",
       " 'Violent J',\n",
       " 'Justin Timberlake',\n",
       " 'Mr Hudson',\n",
       " 'JAY Z',\n",
       " 'Lil Boosie',\n",
       " 'DS',\n",
       " 'DOOM',\n",
       " 'Jay Sean',\n",
       " 'The Roots',\n",
       " 'Cobra Starship',\n",
       " 'Grandmaster Flash',\n",
       " 'Noah23',\n",
       " 'Uncle Kracker',\n",
       " 'Dorrough',\n",
       " 'DJ Green Lantern',\n",
       " 'Killer Mike',\n",
       " 'Beanie Sigel',\n",
       " 'Sara Bareilles',\n",
       " 'Gucci Mane',\n",
       " 'Lloyd',\n",
       " 'k-os',\n",
       " 'Far East Movement',\n",
       " 'DJ Khaled',\n",
       " 'Grand Puba',\n",
       " 'Twista',\n",
       " 'Slaughterhouse',\n",
       " 'T-Pain, Ludacris',\n",
       " 'Method Man',\n",
       " 'Miley Cyrus',\n",
       " 'Busdriver',\n",
       " 'Carrie Underwood',\n",
       " 'Guru',\n",
       " 'Enrique Iglesias',\n",
       " 'Travie McCoy',\n",
       " 'Young Money Entertainment',\n",
       " 'Pitbull',\n",
       " 'Sa-Ra Creative Partners',\n",
       " 'L.E.G.A.C.Y.',\n",
       " 'Alicia Keys',\n",
       " 'Young Jeezy',\n",
       " 'Artists for Haiti',\n",
       " 'Hannah Montana',\n",
       " 'Jason Derulo',\n",
       " 'Rakim',\n",
       " 'Romeo',\n",
       " 'Raekwon',\n",
       " 'Britney Spears',\n",
       " 'Ciara',\n",
       " 'Leighton Meester',\n",
       " \"Cam'ron\",\n",
       " 'Madadam',\n",
       " 'La Roux',\n",
       " 'Jordin Sparks',\n",
       " 'Clipse',\n",
       " 'Plague Language',\n",
       " 'Bow Wow',\n",
       " 'Trick Daddy',\n",
       " 'Jay-Z',\n",
       " 'Randy Travis',\n",
       " 'Jerrod Niemann',\n",
       " 'The Band Perry',\n",
       " 'Havoc',\n",
       " 'Noah23 & Madadam',\n",
       " 'Mims',\n",
       " 'Willy Northpole',\n",
       " 'Neon Trees',\n",
       " 'Big Scoob',\n",
       " 'Gorilla Zoe',\n",
       " 'Warren G',\n",
       " 'Rihanna',\n",
       " 'Train',\n",
       " 'Mike Posner',\n",
       " 'Orianthi',\n",
       " 'Danny!',\n",
       " 'Hell Rell',\n",
       " 'Street Sweeper Social Club',\n",
       " 'Iyaz',\n",
       " 'Pastor Troy',\n",
       " 'Asher Roth',\n",
       " 'Jamie Foxx',\n",
       " 'Lord Kufu',\n",
       " 'The Black Eyed Peas',\n",
       " 'Jadakiss',\n",
       " 'Nelly',\n",
       " 'Tech N9ne',\n",
       " 'Tede',\n",
       " 'Barenaked Ladies',\n",
       " 'Kid Cudi',\n",
       " 'Trey Songz',\n",
       " 'Mike Jones',\n",
       " \"Triple C's\",\n",
       " 'T-Pain',\n",
       " 'Capone-N-Noreaga',\n",
       " 'Ghostface Killah',\n",
       " '50 Cent',\n",
       " 'Sean Paul',\n",
       " 'Snoop Dogg',\n",
       " 'Hayley Williams',\n",
       " 'Chris Brown',\n",
       " 'Baracuda',\n",
       " 'Decemberists',\n",
       " 'Wynter',\n",
       " 'Brother Ali',\n",
       " 'Esoteric',\n",
       " 'Hopsin',\n",
       " 'Kanye West',\n",
       " 'Keri Hilson',\n",
       " 'Juicy J',\n",
       " 'B.G.',\n",
       " 'Blaq Poet',\n",
       " 'The All-American Rejects',\n",
       " 'Classified',\n",
       " 'Flo Rida',\n",
       " 'Sugarland',\n",
       " 'Miranda Lambert',\n",
       " 'Dizzee Rascal',\n",
       " 'Fat Joe',\n",
       " 'Kevin McCall',\n",
       " 'Jeezy',\n",
       " 'Rick Ross',\n",
       " '3OH!3',\n",
       " 'KRS-One & Buckshot',\n",
       " 'Jason Mraz',\n",
       " 'Michael Bublé',\n",
       " 'Glee Cast']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ugh. pyspark.sql.functions.typedLit doesn't exist yet in pyspark to pass the artists to a udf. \n",
    "# So I'm going to switch to pandas for this step\n",
    "\n",
    "entities_pd = annotation.select('entities.result', 'text').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_pd['who'] = [[entity for entity in e_list if entity in artists] for e_list in entities_pd['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>text</th>\n",
       "      <th>who</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[The Library With @NickAustinG, The Concert To...</td>\n",
       "      <td>In The Library With @NickAustinG... He Tryin T...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[@RockStarRenRen]</td>\n",
       "      <td>@RockStarRenRen lol is we going to this concert</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[Kenosha, I\"m, Kenosha]</td>\n",
       "      <td>@bizymare   My son lives in Kenosha, I\"m down ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>@itSHOWTIME how was the concert?</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[Juda]</td>\n",
       "      <td>@audiobebop what time? I'm suppose to go to a ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[@MizzDania]</td>\n",
       "      <td>@MizzDania How was the concert?</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[@S_C_ @SongzYuuup]</td>\n",
       "      <td>The A was poppin @S_C_ @SongzYuuup and jeezy h...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>@melodyxxx LOL u ladies go hard! Are u guys go...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>[I'm, Chile, Haiti, USA]</td>\n",
       "      <td>Look, I'm sorry about Chile and Haiti, but for...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>[Fred, Radio One, PAJAM]</td>\n",
       "      <td>U r!  had to get Fred cause he was doing a Rad...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>[Decemberists]</td>\n",
       "      <td>Gearing up for The Decemberists concert tonigh...</td>\n",
       "      <td>[Decemberists]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>[]</td>\n",
       "      <td>Getting ready to leave for a concert of an old...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>[&amp;]</td>\n",
       "      <td>@DustinLuminate hey, when ya'll do concerts do...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>[@JonasBrothers +, !!!!!*******]</td>\n",
       "      <td>Listening to some @JonasBrothers + getting rea...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>[Lem, Chrissy]</td>\n",
       "      <td>@chrisettefan No she's the headliner. The conc...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>[@RecruitZero, I'll]</td>\n",
       "      <td>@RecruitZero CONGRATS!! ..And, I'll have you k...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>[Pain2Power Foundation Benefit &amp; Inspirational...</td>\n",
       "      <td>RT @Platinumstroke: @ibhappy  Plz RT! Pain2Pow...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @LiveNation: 500th RT wins $100 CONCERT CAS...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>[NKOTB]</td>\n",
       "      <td>I can't wait to see NKOTB in concert @LiveNati...</td>\n",
       "      <td>[NKOTB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>[NKOTB]</td>\n",
       "      <td>I can't wait to see NKOTB in concert @LiveNati...</td>\n",
       "      <td>[NKOTB]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               result  \\\n",
       "0   [The Library With @NickAustinG, The Concert To...   \n",
       "1                                   [@RockStarRenRen]   \n",
       "2                             [Kenosha, I\"m, Kenosha]   \n",
       "3                                                  []   \n",
       "4                                              [Juda]   \n",
       "5                                        [@MizzDania]   \n",
       "6                                 [@S_C_ @SongzYuuup]   \n",
       "7                                                  []   \n",
       "8                            [I'm, Chile, Haiti, USA]   \n",
       "9                            [Fred, Radio One, PAJAM]   \n",
       "10                                     [Decemberists]   \n",
       "11                                                 []   \n",
       "12                                                [&]   \n",
       "13                   [@JonasBrothers +, !!!!!*******]   \n",
       "14                                     [Lem, Chrissy]   \n",
       "15                               [@RecruitZero, I'll]   \n",
       "16  [Pain2Power Foundation Benefit & Inspirational...   \n",
       "17                                                 []   \n",
       "18                                            [NKOTB]   \n",
       "19                                            [NKOTB]   \n",
       "\n",
       "                                                 text             who  \n",
       "0   In The Library With @NickAustinG... He Tryin T...              []  \n",
       "1     @RockStarRenRen lol is we going to this concert              []  \n",
       "2   @bizymare   My son lives in Kenosha, I\"m down ...              []  \n",
       "3                    @itSHOWTIME how was the concert?              []  \n",
       "4   @audiobebop what time? I'm suppose to go to a ...              []  \n",
       "5                     @MizzDania How was the concert?              []  \n",
       "6   The A was poppin @S_C_ @SongzYuuup and jeezy h...              []  \n",
       "7   @melodyxxx LOL u ladies go hard! Are u guys go...              []  \n",
       "8   Look, I'm sorry about Chile and Haiti, but for...              []  \n",
       "9   U r!  had to get Fred cause he was doing a Rad...              []  \n",
       "10  Gearing up for The Decemberists concert tonigh...  [Decemberists]  \n",
       "11  Getting ready to leave for a concert of an old...              []  \n",
       "12  @DustinLuminate hey, when ya'll do concerts do...              []  \n",
       "13  Listening to some @JonasBrothers + getting rea...              []  \n",
       "14  @chrisettefan No she's the headliner. The conc...              []  \n",
       "15  @RecruitZero CONGRATS!! ..And, I'll have you k...              []  \n",
       "16  RT @Platinumstroke: @ibhappy  Plz RT! Pain2Pow...              []  \n",
       "17  RT @LiveNation: 500th RT wins $100 CONCERT CAS...              []  \n",
       "18  I can't wait to see NKOTB in concert @LiveNati...         [NKOTB]  \n",
       "19  I can't wait to see NKOTB in concert @LiveNati...         [NKOTB]  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_pd.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "who_schema = StructType([\n",
    "                StructField(\"result\", ArrayType(StringType()), True),\n",
    "                StructField(\"text\", StringType(), True),\n",
    "                StructField(\"who\", ArrayType(StringType()), True)\n",
    "                ])\n",
    "\n",
    "who = spark.createDataFrame(entities_pd, schema=who_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(result=['The Library With @NickAustinG', 'The Concert Tonite'], text='In The Library With @NickAustinG... He Tryin To Get On His Jigga Shit... Oh We Goin To The Concert Tonite', who=[]),\n",
       " Row(result=['@RockStarRenRen'], text='@RockStarRenRen lol is we going to this concert', who=[]),\n",
       " Row(result=['Kenosha', 'I\"m', 'Kenosha'], text='@bizymare   My son lives in Kenosha, I\"m down there about a dozen times a year.    The concert was for the Kenosha area home schoolers.', who=[]),\n",
       " Row(result=[], text='@itSHOWTIME how was the concert?', who=[]),\n",
       " Row(result=['Juda'], text=\"@audiobebop what time? I'm suppose to go to a concert tonight with Juda. uhh\", who=[]),\n",
       " Row(result=['@MizzDania'], text='@MizzDania How was the concert?', who=[]),\n",
       " Row(result=['@S_C_ @SongzYuuup'], text='The A was poppin @S_C_ @SongzYuuup and jeezy held the concert down.. Back in tally 2 papers and 2 midterms due tues. # backtoboredom', who=[]),\n",
       " Row(result=[], text='@melodyxxx LOL u ladies go hard! Are u guys going the kid cudi concert on Saturday?', who=[]),\n",
       " Row(result=[\"I'm\", 'Chile', 'Haiti', 'USA'], text=\"Look, I'm sorry about Chile and Haiti, but for real, do we need another benefit concert? COME ON! What about people here, in the USA?\", who=[]),\n",
       " Row(result=['Fred', 'Radio One', 'PAJAM'], text='U r!  had to get Fred cause he was doing a Radio One concert yesterday!  I start in Nov...and u know I got u!  In fact I want PAJAM to d ...', who=[])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who.select('*').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.join(who, on='text', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.drop('result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+--------+-------------------+------------+\n",
      "|text                                                                                                                                        |user_id |t_dt               |who         |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+--------+-------------------+------------+\n",
      "|For free - add your event to our calendar! http://bit.ly/T3lbr #seattle #music #events #event #bands #concerts #calendar #blog              |80949495|2009-11-02 15:10:01|[]          |\n",
      "|Jason Mraz was terrific at Red Rocks Sat night.  It's a truly unique & amazing concert venue.  @http://twitpic.com/ilfxr                    |42220821|2009-09-21 15:27:57|[Jason Mraz]|\n",
      "|My Daughter&#39;s First Orchestra Concert | Opensource, Nonprofits ... http://bit.ly/1mcbz8                                                 |18518302|2009-11-18 17:20:16|[]          |\n",
      "|I have 2 tickets to The Sounds concert tomorrow night at the House of Blues. $30 for both. Let me know if you want them.                    |21316433|2009-09-14 20:09:00|[The Sounds]|\n",
      "|music news: Washington 'Ring' cycle ends with riveting concert http://ow.ly/1621Lr                                                          |12135162|2009-11-16 08:37:38|[]          |\n",
      "|Headed over to Billy Bobs for the Diva Concert with Soap Nation.  If you are in the area... stop on by!!                                    |38184021|2009-08-22 11:01:16|[]          |\n",
      "|Zach Deputy = Amazing. Love just pours outta this guy... From an old concert --> http://htxt.it/aCWP                                        |13445142|2009-08-29 10:47:30|[]          |\n",
      "|@Stony419 Whoops missed your tweet last night. Warren G Concert. It was hilarious!                                                          |18991162|2009-11-17 10:42:51|[]          |\n",
      "|@q100Brittany OMG if i win tickets it would be the best day of my life its my dream to see Miley live at a concert & meet her  :)           |73886845|2009-11-13 13:10:54|[]          |\n",
      "|*dizzy* RT @jeskeets: MTV erects wall to block view of U2's free concert to commemorate the fall of the Berlin wall. — http://bit.ly/XwLxt  |17494046|2009-11-05 21:56:26|[]          |\n",
      "|Fri Nov 27 Dudamel Conducts Salonen & Adams @ Walt Disney Concert Hall Los Angeles http://tinyurl.com/ykk3rt8                               |23047566|2009-11-19 10:20:04|[]          |\n",
      "|Open Platform #LiveNation?: artists/fans can upload own concerts, wikis, ratings, reviews, Twitter, Facebook +more: http://bit.ly/3UAIcI    |75577169|2009-10-29 09:46:51|[]          |\n",
      "|I can't wait to see NKOTB in concert @LiveNation with my $100 concert cash!!http://bit.ly/cT4csz                                            |26809809|2010-01-28 14:18:30|[NKOTB]     |\n",
      "|Dan Auerbach concert review: 11/17 at the Variety Playhouse http://www.waronpop.com                                                         |65071205|2009-11-18 14:49:56|[]          |\n",
      "|Don't miss Star Wars in Concert at the Rose Garden this Wednesday.  We still have rooms available! http://tiny.cc/WDsmT                     |26039487|2009-10-12 13:01:51|[]          |\n",
      "|@itssdanielaa haha nice datesss.;D and oh mann remember how we ate that whole box of cheese its after the mitchel concert! Hahaha           |23403892|2009-09-19 20:29:38|[]          |\n",
      "|Tonight! The Roots Concert & Afterparty l HOB l Doors at 8pm l Show at 9:15pm l Afterparty directly following the show in the Cambridge Room|33565318|2009-06-30 13:38:43|[]          |\n",
      "|Leaving for Bobby Long concert in an hour!!                                                                                                 |31333741|2009-11-05 16:38:30|[]          |\n",
      "|Last night I saw a “Barenaked Ladies” concert.  Total ripoff -- it was just fat ugly women on stage                                         |58601997|2009-10-18 13:25:09|[]          |\n",
      "|We are selling grupo unique tickets for there live concert here in chicago to get yours now call 773-807-6969 dont wait there going quickly!|33258398|2009-08-14 00:02:34|[]          |\n",
      "|Jay-z  Blueprint 3 Concert Tickets On Sale Now!: AUSTIN, TEXAS, November 22nd, Frank Erwin Centre - > http://bit.ly/4bkXjJ                  |47065812|2009-10-28 15:01:13|[]          |\n",
      "|@DustinLuminate hey, when ya'll do concerts do u take your own lighting & sound with you?                                                   |23347429|2009-08-19 22:49:53|[]          |\n",
      "|Right on man! So stoked she's back :) RT @TheophilusL: I wish I can go to a SADE concert all day where everyone just got stoned and made out|36264892|2009-12-25 10:41:40|[]          |\n",
      "|@MrPhifer u going to the concert fam?                                                                                                       |23710147|2009-11-09 17:12:33|[]          |\n",
      "|Man am I excited about Shock G of Digital Underground performing a 1 hour private concert at Affiliate Bash @ #affcon L.A.                  |22053527|2009-11-19 19:02:12|[]          |\n",
      "|Want 2C @songzyuuup (trey songz)& @mariosoultruth (mario) live in concert @ HOB hollywood on 9/29?! RT & Follow us 4 a shot to win!         |17659227|2009-09-23 13:53:25|[]          |\n",
      "|In Hawaii Tonight and Tomorrow  Screening of En Concert, then Jack Johnson and Zach Gill , to benefit Kokua. Tix at  www.hawaiitheatre.com  |19210865|2009-11-13 15:28:43|[]          |\n",
      "|is headed to the rock, is inspired by Brooke Fraser's concert on friday night, and encourages you to check out www.worldvision.org!         |15192038|2008-09-14 10:02:49|[]          |\n",
      "|Be sure and send the Murfreesboro Pulse all of your concert listings and events for next month soon - listings@boropulse.com                |80976799|2009-10-24 08:48:19|[]          |\n",
      "|i really hope i will get to meet @justinbieber at the radio disney concert in orlando!                                                      |28917642|2009-11-17 19:57:21|[]          |\n",
      "|The MJ tribute was good-except for Usher. Why was he trying to make it his concert?! He was showing off and I don't think he was genuine.   |55401665|2010-01-31 21:16:34|[Usher]     |\n",
      "|Final day of vacation is today.  No concert tonight; Cards game at Busch Stadium instead.                                                   |14722589|2009-09-15 12:09:00|[]          |\n",
      "|@st_vincent Your blogotheque concert with Andrew Bird absolutely blew my socks off http://bit.ly/4lTUpX I'm in love.                        |14856008|2009-10-22 01:25:54|[]          |\n",
      "|I'm so stoked for this concert. I'm a concert virgin.                                                                                       |34002860|2009-06-12 18:46:07|[]          |\n",
      "|1. i can NOT wait for the new @theaudition album and 2. i'm in dire need of a concert!                                                      |23559254|2010-03-12 15:53:13|[]          |\n",
      "|@jtshrinersopen Will there be a benefit concert in Vegas on the 17th again?!?!                                                              |57567704|2009-08-03 01:09:13|[]          |\n",
      "|First goal of this year accomplished went to aventura concert next goal hmmm its pending.....                                               |27231729|2010-02-01 00:00:00|[]          |\n",
      "|@mrslasky happy birthday enjoy the Garth Brooks concert for your big day!                                                                   |27013990|2009-11-29 08:40:39|[]          |\n",
      "|LIVE WEBCAM: Mike Perry and the Long Beds currently playing at the Back Stage Concert Series in downtown EC. Watch: http://volumeone.org    |18149671|2009-12-03 20:35:01|[]          |\n",
      "|YouTube to Live Stream Alicia Keys Concert Worldwide [VIDEO]: In October, YouTube hosted one of the biggest live st... http://bit.ly/6LhRnX |34171329|2009-11-26 19:23:39|[]          |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+--------+-------------------+------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample.show(40, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHEN: looking for date-related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_datetime download started this may take some time.\n",
      "Approx size to download 12.8 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# I'm going to start with the date matcher pretrained pipeline\n",
    "\n",
    "date_pipe = PretrainedPipeline(\"match_datetime\", lang=\"en\")\n",
    "\n",
    "date_annotation = date_pipe.transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'user_id', 't_dt', 'who', 'document', 'sentence', 'token', 'date']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_annotation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+------------+\n",
      "|text                                                                                                                                        |t_dt               |result      |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+------------+\n",
      "|For free - add your event to our calendar! http://bit.ly/T3lbr #seattle #music #events #event #bands #concerts #calendar #blog              |2009-11-02 15:10:01|[]          |\n",
      "|Jason Mraz was terrific at Red Rocks Sat night.  It's a truly unique & amazing concert venue.  @http://twitpic.com/ilfxr                    |2009-09-21 15:27:57|[]          |\n",
      "|My Daughter&#39;s First Orchestra Concert | Opensource, Nonprofits ... http://bit.ly/1mcbz8                                                 |2009-11-18 17:20:16|[2020/09/08]|\n",
      "|I have 2 tickets to The Sounds concert tomorrow night at the House of Blues. $30 for both. Let me know if you want them.                    |2009-09-14 20:09:00|[2020/05/20]|\n",
      "|music news: Washington 'Ring' cycle ends with riveting concert http://ow.ly/1621Lr                                                          |2009-11-16 08:37:38|[]          |\n",
      "|Headed over to Billy Bobs for the Diva Concert with Soap Nation.  If you are in the area... stop on by!!                                    |2009-08-22 11:01:16|[]          |\n",
      "|Zach Deputy = Amazing. Love just pours outta this guy... From an old concert --> http://htxt.it/aCWP                                        |2009-08-29 10:47:30|[]          |\n",
      "|@Stony419 Whoops missed your tweet last night. Warren G Concert. It was hilarious!                                                          |2009-11-17 10:42:51|[]          |\n",
      "|@q100Brittany OMG if i win tickets it would be the best day of my life its my dream to see Miley live at a concert & meet her  :)           |2009-11-13 13:10:54|[]          |\n",
      "|*dizzy* RT @jeskeets: MTV erects wall to block view of U2's free concert to commemorate the fall of the Berlin wall. — http://bit.ly/XwLxt  |2009-11-05 21:56:26|[]          |\n",
      "|Fri Nov 27 Dudamel Conducts Salonen & Adams @ Walt Disney Concert Hall Los Angeles http://tinyurl.com/ykk3rt8                               |2009-11-19 10:20:04|[2020/11/27]|\n",
      "|Open Platform #LiveNation?: artists/fans can upload own concerts, wikis, ratings, reviews, Twitter, Facebook +more: http://bit.ly/3UAIcI    |2009-10-29 09:46:51|[]          |\n",
      "|I can't wait to see NKOTB in concert @LiveNation with my $100 concert cash!!http://bit.ly/cT4csz                                            |2010-01-28 14:18:30|[]          |\n",
      "|Dan Auerbach concert review: 11/17 at the Variety Playhouse http://www.waronpop.com                                                         |2009-11-18 14:49:56|[]          |\n",
      "|Don't miss Star Wars in Concert at the Rose Garden this Wednesday.  We still have rooms available! http://tiny.cc/WDsmT                     |2009-10-12 13:01:51|[]          |\n",
      "|@itssdanielaa haha nice datesss.;D and oh mann remember how we ate that whole box of cheese its after the mitchel concert! Hahaha           |2009-09-19 20:29:38|[]          |\n",
      "|Tonight! The Roots Concert & Afterparty l HOB l Doors at 8pm l Show at 9:15pm l Afterparty directly following the show in the Cambridge Room|2009-06-30 13:38:43|[2020/05/19]|\n",
      "|Leaving for Bobby Long concert in an hour!!                                                                                                 |2009-11-05 16:38:30|[]          |\n",
      "|Last night I saw a “Barenaked Ladies” concert.  Total ripoff -- it was just fat ugly women on stage                                         |2009-10-18 13:25:09|[]          |\n",
      "|We are selling grupo unique tickets for there live concert here in chicago to get yours now call 773-807-6969 dont wait there going quickly!|2009-08-14 00:02:34|[]          |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_annotation.select('text', 't_dt', 'date.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is cool! It is using day-oriented words, like yesterday! I wonder if there is a way to set a reference date (as opposed to today). At least for the \"Radio One concert\" tweet... Doesn't look like there is, but I can use the date it outputs, get their relation with today, and apply to the date.\n",
    "\n",
    "I'm not sure how it got 12/06 from the \"Decemberists concert tonight\" tweet. - maybe december + the 6 hours later?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_annotation = date_annotation.select('text', F.col('date.result').alias('date_result'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/09/08']),\n",
       " Row(date_result=['2020/05/20']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/11/27']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/05/19']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/11/03']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/05/19']),\n",
       " Row(date_result=['2020/03/09']),\n",
       " Row(date_result=['2020/05/20']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/06/19']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/05/19']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/06/05']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2010/02/01']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/05/19']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/05/19']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/05/20']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/11/13']),\n",
       " Row(date_result=['2020/05/19']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/12/06']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/05/19']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/05/18']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/05/08']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/05/19']),\n",
       " Row(date_result=['2020/05/19']),\n",
       " Row(date_result=['2020/01/07']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/10/10']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/05/20']),\n",
       " Row(date_result=['2020/09/13']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/06/20']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/11/14']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=['2020/05/18']),\n",
       " Row(date_result=['2020/04/01']),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[]),\n",
       " Row(date_result=[])]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_annotation.select('date_result').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|max(no_of_dates)|\n",
      "+----------------+\n",
      "|               1|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_annotation.select(F.size(\"date_result\").alias(\"no_of_dates\")).agg({\"no_of_dates\": \"max\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm deciding to take the first date, since in my small sample, no tweet had more than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_annotation = date_annotation.withColumn('date_result', F.col('date_result')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.join(date_annotation, on='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.withColumn('date_result', F.to_date(sample['date_result'],'yyyy/MM/dd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.withColumn('date_diff', F.datediff(F.current_timestamp(), sample['date_result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if date_result is within two weeks of today, get difference, and apply it to timestamp\n",
    "# elif date_result has this year's date. reset the year to match the year of the tweet \n",
    "# (hardcoeded as 10 years)\n",
    "\n",
    "sample = sample.withColumn('when', F.when((col('date_diff') > -14),\n",
    "                                      F.expr(\"date_add(t_dt, date_diff)\"))\\\n",
    "                          .when((F.col('date_diff') < -14) \n",
    "                                & (F.year('date_result') == F.year(F.current_timestamp())), \n",
    "                                F.date_sub('date_result', 3652))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-------------------+------------+-----------+---------+----------+\n",
      "|                text| user_id|               t_dt|         who|date_result|date_diff|      when|\n",
      "+--------------------+--------+-------------------+------------+-----------+---------+----------+\n",
      "|For free - add yo...|80949495|2009-11-02 15:10:01|          []|       null|     null|      null|\n",
      "|Jason Mraz was te...|42220821|2009-09-21 15:27:57|[Jason Mraz]|       null|     null|      null|\n",
      "|My Daughter&#39;s...|18518302|2009-11-18 17:20:16|          []| 2020-09-08|     -112|2010-09-09|\n",
      "|I have 2 tickets ...|21316433|2009-09-14 20:09:00|[The Sounds]| 2020-05-20|       -1|2009-09-13|\n",
      "+--------------------+--------+-------------------+------------+-----------+---------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample.select('*').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.drop('date_result', 'date_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-------------------+------------+----------+\n",
      "|                text| user_id|               t_dt|         who|      when|\n",
      "+--------------------+--------+-------------------+------------+----------+\n",
      "|For free - add yo...|80949495|2009-11-02 15:10:01|          []|      null|\n",
      "|Jason Mraz was te...|42220821|2009-09-21 15:27:57|[Jason Mraz]|      null|\n",
      "|My Daughter&#39;s...|18518302|2009-11-18 17:20:16|          []|2010-09-09|\n",
      "|I have 2 tickets ...|21316433|2009-09-14 20:09:00|[The Sounds]|2009-09-13|\n",
      "|music news: Washi...|12135162|2009-11-16 08:37:38|          []|      null|\n",
      "|Headed over to Bi...|38184021|2009-08-22 11:01:16|          []|      null|\n",
      "|Zach Deputy = Ama...|13445142|2009-08-29 10:47:30|          []|      null|\n",
      "|@Stony419 Whoops ...|18991162|2009-11-17 10:42:51|          []|      null|\n",
      "|@q100Brittany OMG...|73886845|2009-11-13 13:10:54|          []|      null|\n",
      "|*dizzy* RT @jeske...|17494046|2009-11-05 21:56:26|          []|      null|\n",
      "|Fri Nov 27 Dudame...|23047566|2009-11-19 10:20:04|          []|2010-11-28|\n",
      "|Open Platform #Li...|75577169|2009-10-29 09:46:51|          []|      null|\n",
      "|I can't wait to s...|26809809|2010-01-28 14:18:30|     [NKOTB]|      null|\n",
      "|Dan Auerbach conc...|65071205|2009-11-18 14:49:56|          []|      null|\n",
      "|Don't miss Star W...|26039487|2009-10-12 13:01:51|          []|      null|\n",
      "|@itssdanielaa hah...|23403892|2009-09-19 20:29:38|          []|      null|\n",
      "|Tonight! The Root...|33565318|2009-06-30 13:38:43|          []|2009-06-30|\n",
      "|Leaving for Bobby...|31333741|2009-11-05 16:38:30|          []|      null|\n",
      "|Last night I saw ...|58601997|2009-10-18 13:25:09|          []|      null|\n",
      "|We are selling gr...|33258398|2009-08-14 00:02:34|          []|      null|\n",
      "+--------------------+--------+-------------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future: update \"when\" to have a non-hard-coded version of setting the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm back to entitiy recognition. Going to try out some of the other Spark-NLP options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_entity_rec2 = PretrainedPipeline(\"recognize_entities_bert\", lang=\"en\")\n",
    "# annotation_entity2 = pipe_entity_rec2.transform(sample)\n",
    "# annotation_entity2.select('entities.result').show(20, truncate=False)\n",
    "\n",
    "# Oh no, this pretrained pipeline seems to be broken:\n",
    "\n",
    "# \"\"\"IllegalArgumentException: 'requirement failed: Wrong or missing inputCols annotators in BERT_EMBEDDINGS_2f121e7fb129. \n",
    "# Received inputCols: sentence. Make sure such annotators exist in your pipeline, with the right output names and that \n",
    "# they have following annotator types: document, token\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onto_recognize_entities_lg download started this may take some time.\n",
      "Approx size to download 2.3 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pipe_entity_rec4 = PretrainedPipeline(\"onto_recognize_entities_lg\", lang=\"en\")\n",
    "annotation_entity4 = pipe_entity_rec4.transform(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each has slight differences. None of them seem to be far superior. \n",
    "\n",
    "Looking at the NER of the first entries, I'm decided to use Onto_Lg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                                                                                                 |result                                                                                                                                                                      |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                                                                              |[For, free, -, add, your, event, to, our, calendar, !, http://bit.ly/T3lbr, #seattle, #music, #events, #event, #bands, #concerts, #calendar, #blog]                         |\n",
      "|[B-PERSON, I-PERSON, O, O, O, B-LOC, I-LOC, B-TIME, I-TIME, O, O, O, O, O, O, O, O, O, O, O, O]                                                                        |[Jason, Mraz, was, terrific, at, Red, Rocks, Sat, night, ., It, 's, a, truly, unique, &, amazing, concert, venue, ., @http://twitpic.com/ilfxr]                             |\n",
      "|[O, O, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, O, O, O, O, O]                                                                                                         |[My, Daughter&#39;, s, First, Orchestra, Concert, |, Opensource, ,, Nonprofits, ., ., ., http://bit.ly/1mcbz8]                                                              |\n",
      "|[O, O, B-CARDINAL, O, O, O, O, O, B-TIME, I-TIME, O, B-FAC, I-FAC, I-FAC, I-FAC, O, B-CARDINAL, O, O, O, O, O, O, O, O, O, O, O]                                       |[I, have, 2, tickets, to, The, Sounds, concert, tomorrow, night, at, the, House, of, Blues, ., $30, for, both, ., Let, me, know, if, you, want, them, .]                    |\n",
      "|[O, O, O, B-ORG, O, O, O, O, O, O, O, O, O]                                                                                                                            |[music, news, :, Washington, ', Ring, ', cycle, ends, with, riveting, concert, http://ow.ly/1621Lr]                                                                         |\n",
      "|[O, O, O, B-PERSON, I-PERSON, O, B-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]|[Headed, over, to, Billy, Bobs, for, the, Diva, Concert, with, Soap, Nation, ., If, you, are, in, the, area, ., ., ., stop, on, by, !, !]                                   |\n",
      "|[B-PERSON, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                                                                       |[Zach, Deputy, =, Amazing, ., Love, just, pours, outta, this, guy, ., .., From, an, old, concert, -->, http://htxt.it/aCWP]                                                 |\n",
      "|[O, O, O, O, O, O, B-TIME, I-TIME, O, B-ORG, I-ORG, I-ORG, O, O, O, O, O]                                                                                              |[@, Stony419, Whoops, missed, your, tweet, last, night, ., Warren, G, Concert, ., It, was, hilarious, !]                                                                    |\n",
      "|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PERSON, O, O, O, O, O, O, O, O]                                                                      |[@, q100Brittany, OMG, if, i, win, tickets, it, would, be, the, best, day, of, my, life, its, my, dream, to, see, Miley, live, at, a, concert, &, meet, her, :)]            |\n",
      "|[O, O, O, O, O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-GPE, O, O, O, O]                                                                           |[*, dizzy, *, RT, @, jeskeets, :, MTV, erects, wall, to, block, view, of, U2's, free, concert, to, commemorate, the, fall, of, the, Berlin, wall, ., —, http://bit.ly/XwLxt]|\n",
      "|[B-TIME, I-TIME, I-TIME, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, B-ORG, I-ORG, I-ORG, I-ORG, B-GPE, I-GPE, O]                                                            |[Fri, Nov, 27, Dudamel, Conducts, Salonen, &, Adams, @, Walt, Disney, Concert, Hall, Los, Angeles, http://tinyurl.com/ykk3rt8]                                              |\n",
      "|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG, O, O, O, O, O, O]                                                                                                 |[Open, Platform, #LiveNation?:, artists/fans, can, upload, own, concerts, ,, wikis, ,, ratings, ,, reviews, ,, Twitter, ,, Facebook, +, more, :, http://bit.ly/3UAIcI]      |\n",
      "|[O, O, O, O, O, O, B-ORG, O, O, O, B-ORG, O, O, B-CARDINAL, O, O]                                                                                                      |[I, ca, n't, wait, to, see, NKOTB, in, concert, @, LiveNation, with, my, $100, concert, cash!!http://bit.ly/cT4csz]                                                         |\n",
      "|[B-PERSON, I-PERSON, O, O, O, B-DATE, O, O, B-ORG, I-ORG, O]                                                                                                           |[Dan, Auerbach, concert, review, :, 11/17, at, the, Variety, Playhouse, http://www.waronpop.com]                                                                            |\n",
      "|[O, O, O, B-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, O, B-FAC, I-FAC, I-FAC, O, B-DATE, O, O, O, O, O, O, O, O]                                       |[Do, n't, miss, Star, Wars, in, Concert, at, the, Rose, Garden, this, Wednesday, ., We, still, have, rooms, available, !, http://tiny.cc/WDsmT]                             |\n",
      "|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                                                      |[@, itssdanielaa, haha, nice, datesss, ., ;, D, and, oh, mann, remember, how, we, ate, that, whole, box, of, cheese, its, after, the, mitchel, concert, !, Hahaha]          |\n",
      "|[B-TIME, O, O, O, O, O, O, O, O, O, O, O, B-TIME, O, O, O, O, O, O, O, O, O, O, O, B-FAC, I-FAC, I-FAC]                                                                |[Tonight, !, The, Roots, Concert, &, Afterparty, l, HOB, l, Doors, at, 8pm, l, Show, at, 9:15pm, l, Afterparty, directly, following, the, show, in, the, Cambridge, Room]   |\n",
      "|[O, O, B-PERSON, I-PERSON, O, O, B-TIME, I-TIME, O, O]                                                                                                                 |[Leaving, for, Bobby, Long, concert, in, an, hour, !, !]                                                                                                                    |\n",
      "|[B-TIME, I-TIME, O, O, O, O, B-WORK_OF_ART, I-WORK_OF_ART, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                                   |[Last, night, I, saw, a, “, Barenaked, Ladies, ”, concert, ., Total, ripoff, --, it, was, just, fat, ugly, women, on, stage]                                                |\n",
      "|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-CARDINAL, O, O, O, O, O, O]                                                                                   |[We, are, selling, grupo, unique, tickets, for, there, live, concert, here, in, chicago, to, get, yours, now, call, 773-807-6969, dont, wait, there, going, quickly, !]     |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at ner and tokens together. I'll use any 'FAC', 'GEP' or 'LOC' NER tags as the location.\n",
    "annotation_entity4.select('ner.result', 'token.result').show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_pd = annotation_entity4.select('text', \n",
    "                                   F.col('ner.result').alias('ner'), \n",
    "                                   F.col('token.result').alias('token'))\\\n",
    "                            .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ners = ['FAC', 'GPE', 'LOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = []\n",
    "for ners, tokens in zip(loc_pd['ner'], loc_pd['token']):\n",
    "    location = []\n",
    "    for ner, token in zip(ners, tokens):\n",
    "        if any(target_ner in ner for target_ner in target_ners):\n",
    "            location.append(token)\n",
    "    location = ' '.join(location)\n",
    "    locations.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_pd['location'] = locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ner</th>\n",
       "      <th>token</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>For free - add your event to our calendar! htt...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[For, free, -, add, your, event, to, our, cale...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Jason Mraz was terrific at Red Rocks Sat night...</td>\n",
       "      <td>[B-PERSON, I-PERSON, O, O, O, B-LOC, I-LOC, B-...</td>\n",
       "      <td>[Jason, Mraz, was, terrific, at, Red, Rocks, S...</td>\n",
       "      <td>Red Rocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>My Daughter&amp;#39;s First Orchestra Concert | Op...</td>\n",
       "      <td>[O, O, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O...</td>\n",
       "      <td>[My, Daughter&amp;#39;, s, First, Orchestra, Conce...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I have 2 tickets to The Sounds concert tomorro...</td>\n",
       "      <td>[O, O, B-CARDINAL, O, O, O, O, O, B-TIME, I-TI...</td>\n",
       "      <td>[I, have, 2, tickets, to, The, Sounds, concert...</td>\n",
       "      <td>the House of Blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>music news: Washington 'Ring' cycle ends with ...</td>\n",
       "      <td>[O, O, O, B-ORG, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[music, news, :, Washington, ', Ring, ', cycle...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Headed over to Billy Bobs for the Diva Concert...</td>\n",
       "      <td>[O, O, O, B-PERSON, I-PERSON, O, B-WORK_OF_ART...</td>\n",
       "      <td>[Headed, over, to, Billy, Bobs, for, the, Diva...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Zach Deputy = Amazing. Love just pours outta t...</td>\n",
       "      <td>[B-PERSON, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[Zach, Deputy, =, Amazing, ., Love, just, pour...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>@Stony419 Whoops missed your tweet last night....</td>\n",
       "      <td>[O, O, O, O, O, O, B-TIME, I-TIME, O, B-ORG, I...</td>\n",
       "      <td>[@, Stony419, Whoops, missed, your, tweet, las...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>@q100Brittany OMG if i win tickets it would be...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[@, q100Brittany, OMG, if, i, win, tickets, it...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>*dizzy* RT @jeskeets: MTV erects wall to block...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-ORG, O, O, O, O, O, O,...</td>\n",
       "      <td>[*, dizzy, *, RT, @, jeskeets, :, MTV, erects,...</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  For free - add your event to our calendar! htt...   \n",
       "1  Jason Mraz was terrific at Red Rocks Sat night...   \n",
       "2  My Daughter&#39;s First Orchestra Concert | Op...   \n",
       "3  I have 2 tickets to The Sounds concert tomorro...   \n",
       "4  music news: Washington 'Ring' cycle ends with ...   \n",
       "5  Headed over to Billy Bobs for the Diva Concert...   \n",
       "6  Zach Deputy = Amazing. Love just pours outta t...   \n",
       "7  @Stony419 Whoops missed your tweet last night....   \n",
       "8  @q100Brittany OMG if i win tickets it would be...   \n",
       "9  *dizzy* RT @jeskeets: MTV erects wall to block...   \n",
       "\n",
       "                                                 ner  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [B-PERSON, I-PERSON, O, O, O, B-LOC, I-LOC, B-...   \n",
       "2  [O, O, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O...   \n",
       "3  [O, O, B-CARDINAL, O, O, O, O, O, B-TIME, I-TI...   \n",
       "4        [O, O, O, B-ORG, O, O, O, O, O, O, O, O, O]   \n",
       "5  [O, O, O, B-PERSON, I-PERSON, O, B-WORK_OF_ART...   \n",
       "6  [B-PERSON, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
       "7  [O, O, O, O, O, O, B-TIME, I-TIME, O, B-ORG, I...   \n",
       "8  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "9  [O, O, O, O, O, O, O, B-ORG, O, O, O, O, O, O,...   \n",
       "\n",
       "                                               token            location  \n",
       "0  [For, free, -, add, your, event, to, our, cale...                      \n",
       "1  [Jason, Mraz, was, terrific, at, Red, Rocks, S...           Red Rocks  \n",
       "2  [My, Daughter&#39;, s, First, Orchestra, Conce...                      \n",
       "3  [I, have, 2, tickets, to, The, Sounds, concert...  the House of Blues  \n",
       "4  [music, news, :, Washington, ', Ring, ', cycle...                      \n",
       "5  [Headed, over, to, Billy, Bobs, for, the, Diva...                      \n",
       "6  [Zach, Deputy, =, Amazing, ., Love, just, pour...                      \n",
       "7  [@, Stony419, Whoops, missed, your, tweet, las...                      \n",
       "8  [@, q100Brittany, OMG, if, i, win, tickets, it...                      \n",
       "9  [*, dizzy, *, RT, @, jeskeets, :, MTV, erects,...              Berlin  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_pd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_schema = StructType([\n",
    "                StructField(\"text\", StringType(), True),\n",
    "                StructField(\"ner\", ArrayType(StringType()), True),\n",
    "                StructField(\"token\", ArrayType(StringType()), True),\n",
    "                StructField(\"location\", StringType(), True)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_spk = spark.createDataFrame(loc_pd, schema=loc_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.join(loc_spk, on='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment\n",
    "\n",
    "I'm curious about the differences in results from some of the different sentiment algorithms, but for now, we'll just go with the twitter-based sentiment analysis pretrained pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze_sentiment download started this may take some time.\n",
      "Approx size to download 4.9 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'user_id',\n",
       " 't_dt',\n",
       " 'who',\n",
       " 'when',\n",
       " 'document',\n",
       " 'sentence',\n",
       " 'token',\n",
       " 'checked',\n",
       " 'sentiment']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_sentiment = PretrainedPipeline(\"analyze_sentiment\", lang=\"en\")\n",
    "annotation_sentiment = pipe_sentiment.transform(sample)\n",
    "annotation_sentiment.columns\n",
    "\n",
    "# future note: \"analyze_sentimentdl_use_twitter\" --> Can not find the model to download please check the name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------+\n",
      "|text                                                                                                                                      |result                                            |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------+\n",
      "|For free - add your event to our calendar! http://bit.ly/T3lbr #seattle #music #events #event #bands #concerts #calendar #blog            |[positive, positive]                              |\n",
      "|Jason Mraz was terrific at Red Rocks Sat night.  It's a truly unique & amazing concert venue.  @http://twitpic.com/ilfxr                  |[positive, positive, na]                          |\n",
      "|My Daughter&#39;s First Orchestra Concert | Opensource, Nonprofits ... http://bit.ly/1mcbz8                                               |[negative, negative, negative, negative, na]      |\n",
      "|I have 2 tickets to The Sounds concert tomorrow night at the House of Blues. $30 for both. Let me know if you want them.                  |[positive, positive, positive]                    |\n",
      "|music news: Washington 'Ring' cycle ends with riveting concert http://ow.ly/1621Lr                                                        |[negative]                                        |\n",
      "|Headed over to Billy Bobs for the Diva Concert with Soap Nation.  If you are in the area... stop on by!!                                  |[negative, positive, negative, negative, negative]|\n",
      "|Zach Deputy = Amazing. Love just pours outta this guy... From an old concert --> http://htxt.it/aCWP                                      |[positive, negative, negative]                    |\n",
      "|@Stony419 Whoops missed your tweet last night. Warren G Concert. It was hilarious!                                                        |[positive, positive, positive]                    |\n",
      "|@q100Brittany OMG if i win tickets it would be the best day of my life its my dream to see Miley live at a concert & meet her  :)         |[positive]                                        |\n",
      "|*dizzy* RT @jeskeets: MTV erects wall to block view of U2's free concert to commemorate the fall of the Berlin wall. — http://bit.ly/XwLxt|[negative, na]                                    |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotation_sentiment.select('text', 'sentiment.result').show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sentiment analysis seems like it is not doing a great job with these tweets (a lot of negative). I wish the twitter-trained one was working! But I'll continue.\n",
    "\n",
    "Since the sentiment analysis returns a list, I'll switch to pandas to calculate the balance of the sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pd = annotation_sentiment.select('text','sentiment.result').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pd['sentiment'] = [sum([1 if s == 'positive' else -1 if s == 'negative' else 0 for s in s_list]) for s_list in sentiment_pd['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>result</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>For free - add your event to our calendar! htt...</td>\n",
       "      <td>[positive, positive]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Jason Mraz was terrific at Red Rocks Sat night...</td>\n",
       "      <td>[positive, positive, na]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>My Daughter&amp;#39;s First Orchestra Concert | Op...</td>\n",
       "      <td>[negative, negative, negative, negative, na]</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I have 2 tickets to The Sounds concert tomorro...</td>\n",
       "      <td>[positive, positive, positive]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>music news: Washington 'Ring' cycle ends with ...</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  For free - add your event to our calendar! htt...   \n",
       "1  Jason Mraz was terrific at Red Rocks Sat night...   \n",
       "2  My Daughter&#39;s First Orchestra Concert | Op...   \n",
       "3  I have 2 tickets to The Sounds concert tomorro...   \n",
       "4  music news: Washington 'Ring' cycle ends with ...   \n",
       "\n",
       "                                         result  sentiment  \n",
       "0                          [positive, positive]          2  \n",
       "1                      [positive, positive, na]          2  \n",
       "2  [negative, negative, negative, negative, na]         -4  \n",
       "3                [positive, positive, positive]          3  \n",
       "4                                    [negative]         -1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_schema = StructType([\n",
    "                StructField(\"text\", StringType(), True),\n",
    "                StructField(\"result\", ArrayType(StringType()), True),\n",
    "                StructField(\"sentiment\", IntegerType(), True)\n",
    "                ])\n",
    "\n",
    "sentiment = spark.createDataFrame(sentiment_pd, schema=sentiment_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.join(sentiment.select('text', 'sentiment'), on='text', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.withColumn('sentiment', F.when(F.col('sentiment') > 0, 'positive')\\\n",
    "                                 .when(F.col('sentiment') == 0, 'neutral')\\\n",
    "                                 .when(F.col('sentiment') < 0, 'negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-------------------+------------+----------+---------+\n",
      "|                text| user_id|               t_dt|         who|      when|sentiment|\n",
      "+--------------------+--------+-------------------+------------+----------+---------+\n",
      "|For free - add yo...|80949495|2009-11-02 15:10:01|          []|      null| positive|\n",
      "|Jason Mraz was te...|42220821|2009-09-21 15:27:57|[Jason Mraz]|      null| positive|\n",
      "|My Daughter&#39;s...|18518302|2009-11-18 17:20:16|          []|2010-09-09| negative|\n",
      "|I have 2 tickets ...|21316433|2009-09-14 20:09:00|[The Sounds]|2009-09-13| positive|\n",
      "|music news: Washi...|12135162|2009-11-16 08:37:38|          []|      null| negative|\n",
      "+--------------------+--------+-------------------+------------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audience\n",
    "\n",
    "Short cut. If tweet has I - then the twitter user.\n",
    "\n",
    "**Future: perhaps use the NER to determine the subject (but not the performer) or POS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, my attempt to use the POS tagger didn't work for today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pos = sample.withColumnRenamed('text', 't_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tagger = PerceptronApproach() \\\n",
    "#     .setInputCols([\"token\", \"document\"]) \\\n",
    "#     .setOutputCol(\"pos\") \\\n",
    "#     .setNIterations(5)\\\n",
    "#     .fit() # I'm not sure where to get the training data set for this....\n",
    "\n",
    "# finisher = finisher = Finisher() \\\n",
    "#      .setInputCols(['pos']) \\\n",
    "#      .setCleanAnnotations(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline()\\\n",
    "#                .setStages([\n",
    "#                     documentAssembler,\n",
    "#                     tokenizer,\n",
    "#                     pos_tagger,\n",
    "#                     finisher\n",
    "#                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.transform(sample_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So going with a simple solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "finisher = finisher = Finisher() \\\n",
    "     .setInputCols(['lemma']) \\\n",
    "     .setCleanAnnotations(False)\n",
    "\n",
    "pipeline = Pipeline() \\\n",
    "     .setStages([\n",
    "           documentAssembler,\n",
    "           tokenizer,\n",
    "           normalizer,\n",
    "           lemmatizer,\n",
    "           finisher\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lemma = sample.withColumnRenamed('text', 't_text')\n",
    "sample_lemma = pipeline.fit(sample_lemma).transform(sample_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|finished_lemma                                                                                                                                    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[for, free, add, you, event, to, we, calendar, httpbitlytlbr, seattle, music, event, event, band, concert, calendar, blog]                        |\n",
      "|[jason, mraz, be, terrific, at, red, rock, sit, night, it, a, truly, unique, amazing, concert, venue, httptwitpiccomilfxr]                        |\n",
      "|[i, daughter, first, orchestra, concert, opensource, nonprofits, httpbitlymcbz]                                                                   |\n",
      "|[i, have, ticket, to, the, sound, concert, tomorrow, night, at, the, house, of, blue, for, both, let, i, know, if, you, want, they]               |\n",
      "|[music, news, washington, ring, cycle, end, with, rivet, concert, httpowlylr]                                                                     |\n",
      "|[head, over, to, billy, bob, for, the, diva, concert, with, soap, nation, if, you, be, in, the, area, stop, on, by]                               |\n",
      "|[zach, deputy, amazing, love, just, pour, outta, this, guy, from, an, old, concert, httphtxtitacwp]                                               |\n",
      "|[stony, whoop, miss, you, tweet, last, night, warren, g, concert, it, be, hilarious]                                                              |\n",
      "|[qbrittany, omg, if, i, win, ticket, it, would, be, the, good, day, of, i, life, it, i, dream, to, see, miley, live, at, a, concert, meet, she]   |\n",
      "|[dizzy, rt, jeskeets, mtv, erect, wall, to, block, view, of, we, free, concert, to, commemorate, the, fall, of, the, berlin, wall, httpbitlyxwlxt]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_lemma.select('finished_lemma').show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lemma = sample_lemma.withColumn('audience', F.when(F.array_contains(sample_lemma['finished_lemma'],'i'), sample_lemma['user_id'])\\\n",
    "                                 .when(F.array_contains(sample_lemma['finished_lemma'], 'we'), sample_lemma['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.join(sample_lemma.select(F.col('t_text').alias('text'), 'audience'), on='text', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-------------------+------------+----------+---------+--------+\n",
      "|                text| user_id|               t_dt|         who|      when|sentiment|audience|\n",
      "+--------------------+--------+-------------------+------------+----------+---------+--------+\n",
      "|For free - add yo...|80949495|2009-11-02 15:10:01|          []|      null| positive|80949495|\n",
      "|Jason Mraz was te...|42220821|2009-09-21 15:27:57|[Jason Mraz]|      null| positive|    null|\n",
      "|My Daughter&#39;s...|18518302|2009-11-18 17:20:16|          []|2010-09-09| negative|18518302|\n",
      "|I have 2 tickets ...|21316433|2009-09-14 20:09:00|[The Sounds]|2009-09-13| positive|21316433|\n",
      "|music news: Washi...|12135162|2009-11-16 08:37:38|          []|      null| negative|    null|\n",
      "|Headed over to Bi...|38184021|2009-08-22 11:01:16|          []|      null| negative|    null|\n",
      "|Zach Deputy = Ama...|13445142|2009-08-29 10:47:30|          []|      null| negative|    null|\n",
      "|@Stony419 Whoops ...|18991162|2009-11-17 10:42:51|          []|      null| positive|    null|\n",
      "|@q100Brittany OMG...|73886845|2009-11-13 13:10:54|          []|      null| positive|73886845|\n",
      "|*dizzy* RT @jeske...|17494046|2009-11-05 21:56:26|          []|      null| negative|17494046|\n",
      "+--------------------+--------+-------------------+------------+----------+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyspark-env)\n",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
